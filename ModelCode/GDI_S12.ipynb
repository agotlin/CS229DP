{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specs for running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING SCRIPT!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "machine_to_run_script = 'Sherlock' # 'Sherlock', 'local'\n",
    "spatial_component = 'ANet' # 'vgg16', 'ANet', 'dummy'\n",
    "temporal_component = '1dconv' # '1dconv', 'lstm'\n",
    "type_of_input = 'video' # 'frame', 'video'\n",
    "\n",
    "print('STARTING SCRIPT!!!!!!!!!!!!!!!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-11 22:49:23\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(1)\n",
    "rn.seed(1)\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1)\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "K.set_session(sess)\n",
    "import sys\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv1D,MaxPooling1D,Conv2D,MaxPooling2D\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TerminateOnNaN\n",
    "import keras.regularizers\n",
    "import scipy\n",
    "import math\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import linregress\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "import collections\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from time import time\n",
    "import datetime\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to load data\n",
    "\n",
    "def ImportImage(filepath):\n",
    "    #Check if file path exists\n",
    "    img = Image.open(filepath)\n",
    "    #img = cv2.imread(filepath, 3)\n",
    "    return np.array(img)\n",
    "\n",
    "def windows(data, size, sample_stride): # define time windows to create each training example\n",
    "    start = 0\n",
    "    while start < data.count():\n",
    "        yield int(start), int(start + size)\n",
    "        start += sample_stride\n",
    "\n",
    "def hollywood(data_full, input_window_size, sample_stride): # make video files \n",
    "    list_of_examples = []\n",
    "    labels = np.empty((0))\n",
    "    if machine_to_run_script == 'local':\n",
    "        for (start, end) in windows(data_full['rownum'], input_window_size, sample_stride):   \n",
    "            if(end < data_full.shape[0] and # we are not at the end of the total frames\n",
    "                len(data_full['rownum'][start:end]) == input_window_size and  # not sure\n",
    "                int(imagepaths_wlabels['image_path'][start][21:29])==int(imagepaths_wlabels['image_path'][end-1][21:29])):  # the end patientID = start patiendID\n",
    "                # Pull ten frames, crop the images, stack them\n",
    "                ten_frames = np.array([ImportImage(img) for img in data_full['image_path'][start:end].values])\n",
    "                if spatial_component == 'vgg16': # crop images to fit into vgg16 model architecture\n",
    "                    ten_frames_crops_res = ten_frames[:,16::2, 50:274, :]\n",
    "                    ten_frames_crops_res = ten_frames_crops_res[:,0:224, :, :]\n",
    "                    list_of_examples.append(ten_frames_crops_res)\n",
    "                else:\n",
    "                    #list_of_examples.append(ten_frames)\n",
    "                    list_of_examples.append(ten_frames[:,:, 0:339, :])\n",
    "                labels = np.append(labels,data_full['labels'][start])          \n",
    "    elif machine_to_run_script == 'Sherlock':\n",
    "        for (start, end) in windows(data_full['rownum'], input_window_size, sample_stride):   \n",
    "            if(end < data_full.shape[0] and # we are not at the end of the total frames\n",
    "                len(data_full['rownum'][start:end]) == input_window_size and  # not sure\n",
    "                int(imagepaths_wlabels['patient_ID'][start])==int(imagepaths_wlabels['patient_ID'][end-1])):  # the end patientID = start patiendID\n",
    "                # Pull ten frames, crop the images, stack them\n",
    "                # Check that every file in the frame_sequence exists\n",
    "                file_names = data_full['image_path'][start:end].values\n",
    "                all_files_exist = True\n",
    "                for i, file in enumerate(file_names):\n",
    "                    if os.path.isfile(file) == False:\n",
    "                        all_files_exist = False\n",
    "                if all_files_exist == True:\n",
    "                    ten_frames = np.array([ImportImage(img) for img in file_names])\n",
    "                    if spatial_component == 'vgg16': # crop images to fit into vgg16 model architecture\n",
    "                        ten_frames_crops_res = ten_frames[:,16::2, 50:274, :]\n",
    "                        ten_frames_crops_res = ten_frames_crops_res[:,0:224, :, :]\n",
    "                        list_of_examples.append(ten_frames_crops_res)\n",
    "                    else:\n",
    "                        #list_of_examples.append(ten_frames)\n",
    "                        list_of_examples.append(ten_frames[:,:, 0:339, :])\n",
    "                    labels = np.append(labels,data_full['labels'][start])          \n",
    "            \n",
    "    return np.array(list_of_examples), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING DATA CREATION\n",
      "2018-12-11 22:50:49\n",
      "(9, 7, 480, 339, 3)\n",
      "finished normalizing\n"
     ]
    }
   ],
   "source": [
    "if type_of_input == 'video':\n",
    "\n",
    "    # Pull in path file\n",
    "    print('BEGINNING DATA CREATION')\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    if machine_to_run_script == 'local':\n",
    "        imagepaths_wlabels = pd.read_csv('./data/imagepath_gdi_allframes_205.csv') # TO USE REGRESSION\n",
    "    elif machine_to_run_script == 'Sherlock':\n",
    "        imagepaths_wlabels = pd.read_csv('./imagepath_gdi_allframes_205_SHER.csv') # TO USE REGRESSION #\n",
    "        #imagepaths_wlabels = pd.read_csv('./data/imagepath_gdi_allframes_205.csv') # TO USE REGRESSION # FOR TESTING\n",
    "\n",
    "    # Create video outputs with labels\n",
    "    frames_per_video = 7\n",
    "    stride_per_video = 85\n",
    "    videos, labels = hollywood(imagepaths_wlabels, frames_per_video, stride_per_video)\n",
    "\n",
    "    print(videos.shape)\n",
    "\n",
    "    # Normalize data\n",
    "    videos_normalized = videos # (videos - videos.mean())/videos.std()\n",
    "    #videos_normalized = (videos - videos.mean())/videos.std()\n",
    "\n",
    "    print('finished normalizing')\n",
    "\n",
    "    # Split data into train and validation\n",
    "    msk = np.random.rand(len(videos_normalized)) < 0.8\n",
    "    train_videos=videos_normalized[msk]\n",
    "    train_videos_labels=labels[msk]\n",
    "    validation_videos=videos_normalized[~msk]\n",
    "    validation_videos_labels=labels[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type_of_input == 'frame':\n",
    "\n",
    "    # Pull in path file\n",
    "    print('BEGINNING DATA CREATION')\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    if machine_to_run_script == 'local':\n",
    "        imagepaths_wlabels = pd.read_csv('./data/imagepath_gdi_10_frames.csv') # TO USE REGRESSION\n",
    "    elif machine_to_run_script == 'Sherlock':\n",
    "        imagepaths_wlabels = pd.read_csv('./imagepath_gdi_allframes_205_SHER.csv') # TO USE REGRESSION #\n",
    "\n",
    "    # Randomly kick out 90% of our data to avoid overflow\n",
    "    msk_filter = np.random.rand(len(imagepaths_wlabels)) < 0.05\n",
    "    imagepaths_wlabels = imagepaths_wlabels[msk_filter]\n",
    "        \n",
    "    msk = np.random.rand(len(imagepaths_wlabels)) < 0.8\n",
    "    train=imagepaths_wlabels[msk]\n",
    "    validation=imagepaths_wlabels[~msk]\n",
    "\n",
    "    train_imgs = np.array([ImportImage(img) for img in train['image_path'].values]) # if os.path.isfile(img) == True\n",
    "#     train_labels = np.array([label for label in train['labels'].values if os.path.isfile(img) == True])\n",
    "    train_labels = np.array([label for label in train['labels'].values])\n",
    "    validation_imgs = np.array([ImportImage(img) for img in validation['image_path'].values]) # if os.path.isfile(img) == True\n",
    "#     validation_labels = np.array([label for label in validation['labels'].values if os.path.isfile(img) == True])\n",
    "    validation_labels = np.array([label for label in validation['labels'].values])\n",
    "    \n",
    "if spatial_component == 'vgg16':\n",
    "    train_imgs = train_imgs[:,16::2, 50:274, :]\n",
    "    train_imgs = train_imgs[:,0:224, :, :]\n",
    "    validation_imgs = validation_imgs[:,16::2, 50:274, :]\n",
    "    validation_imgs = validation_imgs[:,0:224, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking zeros\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking zeros\")\n",
    "\n",
    "if type_of_input == 'frame':\n",
    "    #Check if any images are zeros\n",
    "    mask_t = np.ones(len(train_imgs), dtype=bool)\n",
    "    for i, video in enumerate(train_imgs):\n",
    "        if (np.count_nonzero(video)<1):\n",
    "            #print('all zeros at : ', i)\n",
    "            np.delete(train_imgs,i)\n",
    "            np.delete(train_labels,i)\n",
    "            mask_t[i] = False\n",
    "\n",
    "    train_imgs = train_imgs[mask_t,...]\n",
    "    train_labels = train_labels[mask_t,...]\n",
    "\n",
    "    mask_v = np.ones(len(validation_imgs), dtype=bool)\n",
    "    for i, video in enumerate(validation_imgs):\n",
    "        if (np.count_nonzero(video)<1):\n",
    "            #print('all zeros at : ', i)\n",
    "            np.delete(validation_imgs,i)\n",
    "            np.delete(validation_labels,i)\n",
    "            mask_v = np.ones(len(validation_labels), dtype=bool)\n",
    "            mask_v[i] = False\n",
    "\n",
    "    validation_imgs = validation_imgs[mask_v,...]\n",
    "    validation_labels = validation_labels[mask_v,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images shape :  (9, 7, 480, 339, 3)\n",
      "train labels shape :  (9,)\n",
      "validation images shape :  (0, 7, 480, 339, 3)\n",
      "validation labels shape :  (0,)\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "2018-12-11 22:50:57\n"
     ]
    }
   ],
   "source": [
    "if type_of_input == 'video':\n",
    "    # Check expected shapes and whether data is populated with zeros\n",
    "    print('train images shape : ',train_videos.shape)\n",
    "    print('train labels shape : ',train_videos_labels.shape)\n",
    "    print('validation images shape : ',validation_videos.shape)\n",
    "    print('validation labels shape : ',validation_videos_labels.shape)\n",
    "    print(train_videos[0,1,10:15,15:20,1]) # show a random rectangle of one channel of the the image\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    #Check if any images are zeros\n",
    "    mask_t = np.ones(len(train_videos), dtype=bool)\n",
    "    for i, video in enumerate(train_videos):\n",
    "        if (np.count_nonzero(video)<1):\n",
    "            #print('all zeros at : ', i)\n",
    "            np.delete(train_videos,i)\n",
    "            np.delete(train_videos_labels,i)\n",
    "            mask_t[i] = False\n",
    "\n",
    "    train_videos = train_videos[mask_t,...]\n",
    "    train_videos_labels = train_videos_labels[mask_t,...]\n",
    "\n",
    "    mask_v = np.ones(len(validation_videos), dtype=bool)\n",
    "    for i, video in enumerate(validation_videos):\n",
    "        if (np.count_nonzero(video)<1):\n",
    "            #print('all zeros at : ', i)\n",
    "            np.delete(validation_videos,i)\n",
    "            np.delete(validation_videos_labels,i)\n",
    "            mask_v = np.ones(len(validation_videos), dtype=bool)\n",
    "            mask_v[i] = False\n",
    "\n",
    "    validation_videos = validation_videos[mask_v,...]\n",
    "    validation_videos_labels = validation_videos_labels[mask_v,...]\n",
    "\n",
    "    # print('Adding a little bit')\n",
    "    # train_videos = train_videos + 0.00001\n",
    "    # validation_videos = validation_videos + 0.00001\n",
    "    # print('Added a little bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images shape :  (9, 7, 480, 339, 3)\n",
      "train labels shape :  (9,)\n",
      "validation images shape :  (0, 7, 480, 339, 3)\n",
      "validation labels shape :  (0,)\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    " if type_of_input == 'video':\n",
    "    print('train images shape : ',train_videos.shape)\n",
    "    print('train labels shape : ',train_videos_labels.shape)\n",
    "    print('validation images shape : ',validation_videos.shape)\n",
    "    print('validation labels shape : ',validation_videos_labels.shape)\n",
    "    print(train_videos[0,1,10:15,15:20,1]) # show a random rectangle of one channel of the the image\n",
    "\n",
    "if type_of_input == 'frame':\n",
    "    print('train images shape : ',train_imgs.shape)\n",
    "    print('train labels shape : ',train_labels.shape)\n",
    "    print('validation images shape : ',validation_imgs.shape)\n",
    "    print('validation labels shape : ',validation_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Component of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "\n",
    "checkpoint_folder = \"./cnn_checkpoints_gdicnn\"\n",
    "epochs = 100\n",
    "epochs_drop,drop_factor = (10,0.95)\n",
    "batch_size  = 8\n",
    "if type_of_input == 'video':\n",
    "    video_shape = train_videos[0].shape\n",
    "    frame_shape = train_videos[0][0].shape\n",
    "if type_of_input == 'frame':\n",
    "    frame_shape = train_imgs[0].shape\n",
    "kernel_size = 8\n",
    "conv_dim = 8 # number of kernels\n",
    "initial_lrate = 0.01\n",
    "dropout_amount = 0.7\n",
    "l2_lambda = 10**(-3.5)\n",
    "reg = keras.regularizers.l2(l2_lambda)\n",
    "\n",
    "def step_decay(initial_lrate,epochs_drop,drop_factor):\n",
    "    def step_decay_fcn(epoch):\n",
    "        return initial_lrate * math.pow(drop_factor, math.floor((1+epoch)/epochs_drop))\n",
    "    return step_decay_fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spatial_component == 'vgg16':\n",
    "\n",
    "    # Configure VGG Model:\n",
    "    vgg16_model = keras.applications.vgg16.VGG16() # Download Model\n",
    "    type(vgg16_model) #This is a Keras Functional API need to convert to sequential\n",
    "    Frame_model = Sequential() #Iterate over the functional layers and add it as a stack\n",
    "    for layer in vgg16_model.layers:\n",
    "        Frame_model.add(layer)\n",
    "\n",
    "    # Remove last layer of VGG:\n",
    "    Frame_model.layers.pop()\n",
    "\n",
    "    # Fix the VGG model\n",
    "    for layer in Frame_model.layers: #Since the model is already trained with certain weights, we dont want to change it. Let it be the same\n",
    "        layer.trainable = True # False\n",
    "\n",
    "    # Add a Dense layer to VGG\n",
    "    Frame_model.add(Dense(16, activation='relu')) # Add a connected layer\n",
    "    if type_of_input == 'frame':    \n",
    "        Frame_model.add(Dense(1, activation='linear')) # Add for frame specific\n",
    "    \n",
    "    print(Frame_model.summary())\n",
    "    \n",
    "\n",
    "elif spatial_component == 'dummy':\n",
    "    \n",
    "    Frame_model = Sequential()\n",
    "    Frame_model.add(Conv2D(conv_dim, kernel_size=kernel_size, input_shape=frame_shape, padding='valid', strides = 5))\n",
    "    Frame_model.add(Activation('relu'))\n",
    "    Frame_model.add(BatchNormalization())\n",
    "    Frame_model.add(Dropout(0.9))\n",
    "    Frame_model.add(Flatten())\n",
    "    Frame_model.add(Dense(18,activation='relu'))\n",
    "\n",
    "elif spatial_component == 'ANet':\n",
    "\n",
    "    Frame_model = Sequential()\n",
    "    Frame_model.add(Conv2D(conv_dim, kernel_size=kernel_size, input_shape=frame_shape, padding='same'))\n",
    "    Frame_model.add(Activation('relu'))\n",
    "    Frame_model.add(BatchNormalization())\n",
    "    Frame_model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same'))\n",
    "    Frame_model.add(Activation('relu'))\n",
    "    Frame_model.add(BatchNormalization())\n",
    "    Frame_model.add(MaxPooling2D(pool_size=2))\n",
    "    Frame_model.add(Dropout(dropout_amount))\n",
    "    Frame_model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same',kernel_regularizer=reg))\n",
    "    Frame_model.add(Activation('relu'))\n",
    "    Frame_model.add(BatchNormalization())\n",
    "    Frame_model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same',kernel_regularizer=reg))\n",
    "    Frame_model.add(Activation('relu'))\n",
    "    Frame_model.add(BatchNormalization())\n",
    "    Frame_model.add(MaxPooling2D(pool_size=2))\n",
    "    Frame_model.add(Dropout(dropout_amount))\n",
    "    Frame_model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same',kernel_regularizer=reg))\n",
    "    Frame_model.add(Activation('relu'))\n",
    "    Frame_model.add(BatchNormalization())\n",
    "    Frame_model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same',kernel_regularizer=reg))\n",
    "    Frame_model.add(Activation('relu'))\n",
    "    Frame_model.add(BatchNormalization())\n",
    "    Frame_model.add(MaxPooling2D(pool_size=3))\n",
    "    Frame_model.add(Dropout(dropout_amount))\n",
    "    Frame_model.add(Flatten())\n",
    "    Frame_model.add(Dense(16,activation='relu'))\n",
    "    if type_of_input == 'frame':\n",
    "        Frame_model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 7, 480, 339, 3)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 7, 16)             165632    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 5, 20)             980       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 4, 20)             0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                1296      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 167,925\n",
      "Trainable params: 167,829\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if type_of_input == 'video':\n",
    "    if temporal_component == 'lstm':\n",
    "\n",
    "        # Declare video_model and apply frame_model to each frame\n",
    "        video_input = Input(shape=video_shape) # usually 10 frames that are 224x224x3 each\n",
    "        encoded_frame_sequence = TimeDistributed(Frame_model)(video_input) # Run frame_model on each frame\n",
    "\n",
    "        # Add LSTM                  \n",
    "        encoded_video = LSTM(256)(encoded_frame_sequence)  # the output will be a vector\n",
    "\n",
    "        # Add a linear layer for output of video model\n",
    "        output = Dense(1, activation='linear')(encoded_video)\n",
    "\n",
    "        # Configure video_model\n",
    "        video_model = Model(inputs=video_input, outputs=output)   \n",
    "\n",
    "        video_model.summary()\n",
    "\n",
    "    elif temporal_component == '1dconv':\n",
    "\n",
    "        # Declare video_model and apply frame_model to each frame\n",
    "        video_input = Input(shape=video_shape) # usually 10 frames that are 224x224x3 each\n",
    "        encoded_frame_sequence = TimeDistributed(Frame_model)(video_input) # Run frame_model on each frame\n",
    "\n",
    "        num_filters = 20\n",
    "        kernel_size = 3\n",
    "        activation_conv_layer = 'relu'\n",
    "        max_pool_kernel_size = 2\n",
    "        num_hidden_units_fc_layers_CNN = 16\n",
    "        activations_fc_layers_CNN = 'relu'\n",
    "\n",
    "        # Add 1D convolutions to the sequence (along the time dimension)\n",
    "        conv1 = Conv1D(num_filters, kernel_size,activation=activation_conv_layer)(encoded_frame_sequence)\n",
    "        pool1 = MaxPooling1D(pool_size=max_pool_kernel_size, padding='valid', strides=(1))(conv1)\n",
    "        drop1 = Dropout(0.5)(pool1)\n",
    "        #conv2 = Conv1D(num_filters//5, kernel_size, activation=activation_conv_layer)(pool1) # add additional CNN layer\n",
    "        flat1 = Flatten()(drop1)\n",
    "        fc_layer = Dense(num_hidden_units_fc_layers_CNN, activation=activations_fc_layers_CNN)(flat1) # add first fully connected layer\n",
    "\n",
    "    #     # Add fully connected layers (optional)\n",
    "    #     fc_dict={}\n",
    "    #     fc_dict[1] = Dense(num_hidden_units_fc_layers_CNN[0], activation=activations_fc_layers_CNN[0])(merged) # add first fully connected layer\n",
    "    #         for L in range(2, num_hidden_fc_layers_CNN+1):\n",
    "    #             fc_dict[L] = Dense(num_hidden_units_fc_layers_CNN[L-1], activation=activations_fc_layers_CNN[L-1])(fc_dict[L-1])\n",
    "\n",
    "        # Add a softmax layer for output of video_model \n",
    "        output = Dense(1, activation='linear')(fc_layer)\n",
    "\n",
    "        # Configure video_model\n",
    "        video_model = Model(inputs=[video_input], outputs=output)\n",
    "\n",
    "        video_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model and Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPILING MODEL\n",
      "2018-12-11 22:51:37\n"
     ]
    }
   ],
   "source": [
    "if type_of_input == 'video':       \n",
    "    # Compile model\n",
    "    print('COMPILING MODEL')\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    if not os.path.exists(checkpoint_folder):\n",
    "        os.makedirs(checkpoint_folder)\n",
    "\n",
    "    filepath=checkpoint_folder+\"/weights-{epoch:02d}.hdf5\"\n",
    "\n",
    "    # Create optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False)\n",
    "\n",
    "    # Declare optimizer, lsos function, and reporting metrics\n",
    "    video_model.compile(loss='mse',metrics=['mae'],optimizer=opt)\n",
    "\n",
    "    # Create checkpoints to keep track of weights\n",
    "    checkpoint = \\\n",
    "        ModelCheckpoint(filepath, verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    # Define learning rate function\n",
    "    lr = LearningRateScheduler(step_decay(initial_lrate,epochs_drop,drop_factor))\n",
    "\n",
    "    # Add tensorboard logs\n",
    "    #tensorboard = keras.callbacks.TensorBoard(log_dir='./tensorboard-logs/{}'.format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9 samples, validate on 0 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "# Train Model!\n",
    "\n",
    "if type_of_input == 'video':\n",
    "\n",
    "    history = video_model.fit(train_videos, train_videos_labels, # ,callbacks=[checkpoint,lr,TerminateOnNaN()], #,tensorboard],\n",
    "              validation_data=(validation_videos,validation_videos_labels),\n",
    "              batch_size=batch_size, epochs=epochs,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type_of_input == 'frame':\n",
    "    # Compile model\n",
    "    print('COMPILING MODEL')\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    if not os.path.exists(checkpoint_folder):\n",
    "        os.makedirs(checkpoint_folder)\n",
    "\n",
    "    filepath=checkpoint_folder+\"/weights-{epoch:02d}.hdf5\"\n",
    "\n",
    "    # Create optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False)\n",
    "\n",
    "    # Declare optimizer, lsos function, and reporting metrics\n",
    "    Frame_model.compile(loss='mse',metrics=['mae'],optimizer=opt)\n",
    "\n",
    "    # Create checkpoints to keep track of weights\n",
    "    checkpoint = \\\n",
    "        ModelCheckpoint(filepath, verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    # Define learning rate function\n",
    "    lr = LearningRateScheduler(step_decay(initial_lrate,epochs_drop,drop_factor))\n",
    "\n",
    "    # Add tensorboard logs\n",
    "    #tensorboard = keras.callbacks.TensorBoard(log_dir='./tensorboard-logs/{}'.format(time()))\n",
    "    \n",
    "    history = Frame_model.fit(train_imgs, train_labels, # ,callbacks=[checkpoint,lr,TerminateOnNaN()], #,tensorboard],\n",
    "          validation_data=(validation_imgs,validation_labels),\n",
    "          batch_size=batch_size, epochs=epochs,shuffle=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Predictions and Report Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " if type_of_input == 'video':\n",
    "    Ynew = video_model.predict(validation_videos)\n",
    "    # show the inputs and predicted outputs\n",
    "    for i in range(len(validation_videos)):\n",
    "        print(\"True=%s, Predicted=%s\" % (validation_videos_labels[i], Ynew[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " if type_of_input == 'frame':\n",
    "    Ynew = Frame_model.predict(validation_imgs)\n",
    "    # show the inputs and predicted outputs\n",
    "    for i in range(len(validation_imgs)):\n",
    "        print(\"True=%s, Predicted=%s\" % (validation_labels[i], Ynew[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(conv_dim, kernel_size=kernel_size, input_shape=input_shape, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Dropout(dropout_amount))\n",
    "# model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same',kernel_regularizer=reg))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same',kernel_regularizer=reg))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Dropout(dropout_amount))\n",
    "# model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same',kernel_regularizer=reg))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same',kernel_regularizer=reg))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=3))\n",
    "# model.add(Dropout(dropout_amount))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(last_layer_dim,activation='relu'))\n",
    "# model.add(Dense(18, activation='softmax'))\n",
    "\n",
    "\n",
    "# from skimage import data, color\n",
    "# from skimage.transform import rescale, resize, downscale_local_mean\n",
    "# arr = train_imgs[0]\n",
    "# #arr_resize = scipy.misc.imresize(arr,(224,224,3))\n",
    "# image_resized = resize(arr, (224,224,3), anti_aliasing=false)\n",
    "\n",
    "# print('train images shape : ',train_imgs.shape)\n",
    "# print('validation images shape : ',validation_imgs.shape)\n",
    "\n",
    "# # RESHAPE FOR VGG16\n",
    "# train_imgs_crops_res = train_imgs[:,16::2, 50:274, :]\n",
    "# train_imgs_crops_res = train_imgs_crops_res[:,0:224, :, :]\n",
    "# validation_imgs_crops_res = validation_imgs[:,16::2, 50:274, :]\n",
    "# validation_imgs_crops_res = validation_imgs_crops_res[:,0:224, :, :]\n",
    "\n",
    "# print(train_imgs_crops_res.shape)\n",
    "# print(validation_imgs_crops_res.shape)\n",
    "\n",
    "# print(train_videos.shape)\n",
    "# print(train_videos_labels.shape)\n",
    "# # validation_videos=videos[~msk]\n",
    "# validation_videos_labels=labels[~msk]\n",
    "\n",
    "\n",
    "# # RANDOM ASIDE FOR LINEAR REGRESSION\n",
    "\n",
    "# if machine_to_run_script == 'local':\n",
    "#     imagepaths_wlabels = pd.read_csv('./data/imagepath_gdi_10_frames.csv') # TO USE REGRESSION\n",
    "# elif machine_to_run_script == 'Sherlock':\n",
    "#     imagepaths_wlabels = pd.read_csv('./imagepath_gdi_allframes_205_SHER.csv') # TO USE REGRESSION #\n",
    "\n",
    "# # Randomly kick out 90% of our data to avoid overflow\n",
    "# msk_filter = np.random.rand(len(imagepaths_wlabels)) < 0.01\n",
    "# imagepaths_wlabels = imagepaths_wlabels[msk_filter]\n",
    "\n",
    "# msk = np.random.rand(len(imagepaths_wlabels)) < 0.8\n",
    "# train=imagepaths_wlabels[msk]\n",
    "# validation=imagepaths_wlabels[~msk]\n",
    "\n",
    "# train_imgs = np.array([ImportImage(img) for img in train['image_path'].values]) # if os.path.isfile(img) == True\n",
    "# #     train_labels = np.array([label for label in train['labels'].values if os.path.isfile(img) == True])\n",
    "# train_labels = np.array([label for label in train['labels'].values])\n",
    "# validation_imgs = np.array([ImportImage(img) for img in validation['image_path'].values]) # if os.path.isfile(img) == True\n",
    "# #     validation_labels = np.array([label for label in validation['labels'].values if os.path.isfile(img) == True])\n",
    "# validation_labels = np.array([label for label in validation['labels'].values])\n",
    "    \n",
    "# print('train images shape : ',train_imgs.shape)\n",
    "# print('train labels shape : ',train_labels.shape)\n",
    "# print('validation images shape : ',validation_imgs.shape)\n",
    "# print('validation labels shape : ',validation_labels.shape)\n",
    "\n",
    "\n",
    "# RANDOM ASIDE FOR CALCULATION ZERO-RULE ERROR (DELETE)\n",
    "\n",
    "#     imagepaths_wlabels = pd.read_csv('./data/imagepath_gdi_allframes_205_SHER.csv') # TO USE REGRESSION\n",
    "#     msk = np.random.rand(len(imagepaths_wlabels)) < 0.8\n",
    "#     train=imagepaths_wlabels[msk]\n",
    "#     validation=imagepaths_wlabels[~msk]\n",
    "    \n",
    "#     train_labels = np.array([label for label in train['labels'].values])\n",
    "#     validation_labels = np.array([label for label in validation['labels'].values])\n",
    "    \n",
    "#     train_mean = np.mean(train_labels)\n",
    "#     y_pred = np.ones(len(validation_labels))*train_mean\n",
    "#     y_pred_t = np.ones(len(train_labels))*train_mean\n",
    "    \n",
    "#     rms = math.sqrt(mean_squared_error(validation_labels, y_pred))\n",
    "#     rms_train = math.sqrt(mean_squared_error(train_labels, y_pred_t))\n",
    "    \n",
    "#     print('train labels shape : ',train_labels.shape)\n",
    "#     print('validation labels shape : ',validation_labels.shape)\n",
    "#     print(train_mean)\n",
    "#     print(rms)\n",
    "#     print(rms_train)\n",
    "\n",
    "# train_imgs_reshaped = np.reshape(train_imgs, (train_imgs.shape[0], (train_imgs.shape[1] * train_imgs.shape[2] * train_imgs.shape[3])))\n",
    "# validation_imgs_reshaped = np.reshape(validation_imgs, (validation_imgs.shape[0], (validation_imgs.shape[1] * validation_imgs.shape[2] * validation_imgs.shape[3])))\n",
    "\n",
    "# print(train_imgs_reshaped.shape)\n",
    "# print(validation_imgs_reshaped.shape)\n",
    "# from sklearn import datasets, linear_model\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.datasets import make_regression\n",
    "\n",
    "# regr = linear_model.LinearRegression()\n",
    "\n",
    "# # Train the model using the training sets\n",
    "# regr.fit(train_imgs_reshaped, train_labels)\n",
    "\n",
    "# # Make predictions using the testing set\n",
    "# Y_pred = regr.predict(validation_imgs_reshaped)\n",
    "\n",
    "# # Make predictions using the testing set\n",
    "# Y_pred_train = regr.predict(train_imgs_reshaped)\n",
    "\n",
    "# print(\"Root mean squared error of Linear Regression Val: %.8f\"\n",
    "#       % math.sqrt(mean_squared_error(validation_labels, Y_pred)))\n",
    "\n",
    "# print(\"Root mean squared error of Linear Regression Train: %.8f\"\n",
    "#       % math.sqrt(mean_squared_error(train_labels, Y_pred_train)))\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(train_labels, Y_pred_train, edgecolors=(0, 0, 0))\n",
    "# ax.plot([validation_labels.min(), validation_labels.max()], [validation_labels.min(), validation_labels.max()], 'k--', lw=4)\n",
    "# ax.set_xlabel('GDI True')\n",
    "# ax.set_ylabel('GDI Predicted')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
