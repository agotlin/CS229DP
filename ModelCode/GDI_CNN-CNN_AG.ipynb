{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specs for running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_to_run_script = 'local' # 'Sherlock', 'local'\n",
    "type_of_input = 'video' # 'video' 'frame'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(1)\n",
    "rn.seed(1)\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1)\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "K.set_session(sess)\n",
    "import sys\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv1D,MaxPooling1D,Conv2D,MaxPooling2D\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TerminateOnNaN\n",
    "import keras.regularizers\n",
    "import scipy\n",
    "import math\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import linregress\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "#import cPickle as pickle\n",
    "#from video_process_utils import *\n",
    "import collections\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "#from PIL import Image\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "#import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportImage(filepath):\n",
    "    #print(filepath)\n",
    "    #Check if file path exists\n",
    "    img = Image.open(filepath)\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type_of_input == 'frame':\n",
    "\n",
    "    if machine_to_run_script == 'local':\n",
    "        imagepaths_labels = pd.read_csv('./data/imagepath_gdi_10_frames.csv') # TO USE REGRESSION\n",
    "    elif machine_to_run_script == 'Sherlock':\n",
    "        imagepaths_labels = pd.read_csv('??????/imagepath_gdi_10_frames.csv') # TO USE REGRESSION\n",
    "    #imagepaths_labels = pd.read_csv('./data/imagepath_gdi_10_frames_lnorm.csv') # TO USE CLASSIFICATION\n",
    "    msk = np.random.rand(len(imagepaths_labels)) < 0.8\n",
    "    train=imagepaths_labels[msk]\n",
    "    validation=imagepaths_labels[~msk]\n",
    "    \n",
    "    train_imgs = np.array([ImportImage(img) for img in train['image_path'].values])\n",
    "    train_labels = np.array([label for label in train['labels'].values])\n",
    "    #train_labels = np.array([label for label in train['labels_norm'].values]) # TO USE CLASSIFICATION\n",
    "    validation_imgs = np.array([ImportImage(img) for img in validation['image_path'].values])\n",
    "    validation_labels = np.array([label for label in validation['labels'].values])\n",
    "    #validation_labels = np.array([label for label in validation['labels_norm'].values]) # TO USE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions CODE FOR CREATING GROUPED TIME-SERIES INPUTS\n",
    "\n",
    "def windows(data, size, sample_stride): # define time windows to create each training example\n",
    "    start = 0\n",
    "    while start < data.count():\n",
    "        yield int(start), int(start + size)\n",
    "        start += sample_stride # other common options: (size / 2)\n",
    "\n",
    "# Used for CNN/FFCN input WITHOUT SQL pre-processing\n",
    "def segment_signal(data_full, input_window_size, sample_stride, height = 224, width = 224): \n",
    "    segments_timeseries = np.empty((0, input_window_size, height, width, 3)) # define segment shape for training example input\n",
    "    list_of_examples = []\n",
    "    labels = np.empty((0))\n",
    "    for (start, end) in windows(data_full['rownum'], input_window_size, sample_stride):   \n",
    "        if(end < data_full.shape[0] and # we are not at the end of the total frames\n",
    "            len(data_full['rownum'][start:end]) == input_window_size and  # not sure\n",
    "            int(imagepaths_wlabels['image_path'][start][21:29])==int(imagepaths_wlabels['image_path'][end-1][21:29])):  # the end patientID = start patiendID\n",
    "            # Pull ten frames, crop the images, stack them\n",
    "#             print(data_full['image_path'][start:end].values)\n",
    "            ten_frames = np.array([ImportImage(img) for img in data_full['image_path'][start:end].values])\n",
    "            ten_frames_crops_res = ten_frames[:,16::2, 50:274, :]\n",
    "            ten_frames_crops_res = ten_frames_crops_res[:,0:224, :, :]\n",
    "            #print(segments_timeseries.shape)\n",
    "            list_of_examples.append(ten_frames_crops_res)\n",
    "#             print((np.array(list_of_examples).shape))\n",
    "#             print(labels.shape)\n",
    "            labels = np.append(labels,data_full['labels'][start])          \n",
    "#             print(labels.shape)\n",
    "#             print(start, end)\n",
    "            \n",
    "    return np.array(list_of_examples), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type_of_input == 'video':\n",
    "\n",
    "    #imagepaths_labels = pd.read_csv('./data/imagepath_gdi_10_frames.csv')\n",
    "    if machine_to_run_script == 'local':\n",
    "        imagepaths_wlabels = pd.read_csv('./data/imagepath_gdi_10_frames.csv') # TO USE REGRESSION\n",
    "    elif machine_to_run_script == 'Sherlock':\n",
    "        imagepaths_wlabels = pd.read_csv('.?????/imagepath_gdi_10_frames.csv') # TO USE REGRESSION\n",
    "\n",
    "    videos, labels = segment_signal(imagepaths_wlabels, 10, 1, height = 224, width = 224)\n",
    "\n",
    "    videos_normalized = (videos - videos.mean())/videos.std()\n",
    "    \n",
    "    msk = np.random.rand(len(videos_normalized)) < 0.8\n",
    "    train_videos=videos_normalized[msk]\n",
    "    train_videos_labels=labels[msk]\n",
    "    validation_videos=videos_normalized[~msk]\n",
    "    validation_videos_labels=labels[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images shape :  (59, 10, 224, 224, 3)\n",
      "train labels shape :  (59,)\n",
      "validation images shape :  (12, 10, 224, 224, 3)\n",
      "validation labels shape :  (12,)\n"
     ]
    }
   ],
   "source": [
    "if type_of_input == 'video':\n",
    "\n",
    "    print('train images shape : ',train_videos.shape)\n",
    "    print('train labels shape : ',train_videos_labels.shape)\n",
    "    print('validation images shape : ',validation_videos.shape)\n",
    "    print('validation labels shape : ',validation_videos_labels.shape)\n",
    "    \n",
    "    #print(train_videos[0,1,10:25,10:25,0])\n",
    "\n",
    "    # Check if any images are zeros\n",
    "    for i, video in enumerate(train_videos):\n",
    "        if (np.count_nonzero(video)<1):\n",
    "            print('all zeros at : ', i)\n",
    "    for i, video in enumerate(validation_videos):\n",
    "        if (np.count_nonzero(video)<1):\n",
    "            print('all zeros at : ', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_videos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mcell_name\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_videos' is not defined"
     ]
    }
   ],
   "source": [
    "if type_of_input == 'frame':\n",
    "#     # Resize our Images to 224 x 224 x 3\n",
    "     train_imgs_crops_res = train_videos[0,:,16::2, 50:274, :]\n",
    "     train_imgs_crops_res = train_imgs_crops_res[:,0:224, :, :]\n",
    "#     validation_imgs_crops_res = validation_imgs[:,16::2, 50:274, :]\n",
    "#     validation_imgs_crops_res = validation_imgs_crops_res[:,0:224, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostly unnecessary, but might as well leave it in case we switch to ACNN\n",
    "\n",
    "def step_decay(initial_lrate,epochs_drop,drop_factor):\n",
    "    def step_decay_fcn(epoch):\n",
    "        return initial_lrate * math.pow(drop_factor, math.floor((1+epoch)/epochs_drop))\n",
    "    return step_decay_fcn\n",
    "\n",
    "checkpoint_folder = \"./cnn_checkpoints_gdicnn\"\n",
    "batch_size  = 16\n",
    "num_classes = len(train_labels)\n",
    "epochs = 100\n",
    "epochs_drop,drop_factor = (10,0.)\n",
    "#input_shape = train_imgs_crops_res[0].shape\n",
    "input_shape = train_videos[0].shape\n",
    "kernel_size = 8\n",
    "conv_dim = 16\n",
    "initial_lrate = 0.001\n",
    "dropout_amount = 0.5\n",
    "l2_lambda = 10**(-3.5)\n",
    "reg = keras.regularizers.l2(l2_lambda)\n",
    "last_layer_dim=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 138,457,745\n",
      "Trainable params: 100,201\n",
      "Non-trainable params: 138,357,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if type_of_input == 'frame':\n",
    "\n",
    "    # Resize our Images to 224 x 224 x 3\n",
    "    train_imgs_crops_res = train_imgs[:,16::2, 50:274, :]\n",
    "    train_imgs_crops_res = train_imgs_crops_res[:,0:224, :, :]\n",
    "    validation_imgs_crops_res = validation_imgs[:,16::2, 50:274, :]\n",
    "    validation_imgs_crops_res = validation_imgs_crops_res[:,0:224, :, :]\n",
    "\n",
    "    # Normalize Data\n",
    "    \n",
    "    \n",
    "    # Configure VGG Model:\n",
    "    vgg16_model = keras.applications.vgg16.VGG16() # Download Model\n",
    "    type(vgg16_model) #This is a Keras Functional API need to convert to sequential\n",
    "    Frame_model = Sequential() #Iterate over the functional layers and add it as a stack\n",
    "    for layer in vgg16_model.layers:\n",
    "        Frame_model.add(layer)\n",
    "\n",
    "    # Remove last layer of VGG:\n",
    "    Frame_model.layers.pop()\n",
    "\n",
    "    # Fix the VGG model\n",
    "    for layer in Frame_model.layers: #Since the model is already trained with certain weights, we dont want to change it. Let it be the same\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add a Dense layer to VGG\n",
    "    Frame_model.add(Dense(64, activation='relu')) # Add the last layer Q: Why sigmoid? Why note softmax? Or lienar for regression?                \n",
    "    #Frame_model.add(Dense(18, activation='softmax')) # Add the last layer\n",
    "    Frame_model.add(Dense(1, activation='linear')) # Add the last layer\n",
    "    \n",
    "    Frame_model.summary()\n",
    "    \n",
    "    # Dummy model\n",
    "    \n",
    "    dummy_model = Sequential()\n",
    "    dummy_model.add(Conv2D(conv_dim, kernel_size=kernel_size, input_shape=input_shape, padding='valid', strides = 10))\n",
    "    dummy_model.add(Activation('relu'))\n",
    "    dummy_model.add(BatchNormalization())\n",
    "    dummy_model.add(Flatten())\n",
    "    dummy_model.add(Dense(18,activation='relu'))\n",
    "    dummy_model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 16)        3088      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 22, 22, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 22, 16)        64        \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 18)                139410    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 142,581\n",
      "Trainable params: 142,549\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dummy_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 10, 224, 224, 3)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 10, 18)            560738    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               281600    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 842,595\n",
      "Trainable params: 842,563\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# DUMMY VIDEO MODEL\n",
    "\n",
    "if type_of_input == 'video':\n",
    "\n",
    "    dummy_model = Sequential()\n",
    "    dummy_model.add(Conv2D(conv_dim, kernel_size=kernel_size, input_shape=train_videos[0][0].shape, padding='valid', strides = 5))\n",
    "    dummy_model.add(Activation('relu'))\n",
    "    dummy_model.add(BatchNormalization())\n",
    "    dummy_model.add(Flatten())\n",
    "    dummy_model.add(Dense(18,activation='relu'))\n",
    "\n",
    "    video_input = Input(shape=(10, 224, 224, 3)) # 10 frames that are 224x224x3 each\n",
    "    video_input = Input(shape=train_videos[0].shape) # 10 frames that are 224x224x3 each\n",
    "    encoded_frame_sequence = TimeDistributed(dummy_model)(video_input) # Run frame_model on each frame\n",
    "\n",
    "    # Add LSTM                  \n",
    "    encoded_video = LSTM(256)(encoded_frame_sequence)  # the output will be a vector\n",
    "\n",
    "    # Add a linear layer for output of video model\n",
    "    output = Dense(1, activation='linear')(encoded_video)\n",
    "\n",
    "    # Configure video_model\n",
    "    video_model = Model(inputs=video_input, outputs=output)   \n",
    "    \n",
    "    video_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type_of_input == 'video':\n",
    "\n",
    "    # Configure VGG Model:\n",
    "    vgg16_model = keras.applications.vgg16.VGG16() # Download Model\n",
    "    type(vgg16_model) #This is a Keras Functional API need to convert to sequential\n",
    "    Frame_model = Sequential() #Iterate over the functional layers and add it as a stack\n",
    "    for layer in vgg16_model.layers:\n",
    "        Frame_model.add(layer)\n",
    "\n",
    "    # Remove last layer of VGG:\n",
    "    Frame_model.layers.pop()\n",
    "\n",
    "    # Fix the VGG model\n",
    "    for layer in Frame_model.layers: #Since the model is already trained with certain weights, we dont want to change it. Let it be the same\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add a Dense layer to VGG\n",
    "    Frame_model.add(Dense(32, activation='relu')) # Add a connected layer\n",
    "\n",
    "    video_input = Input(shape=(10, 224, 224, 3)) # 10 frames that are 224x224x3 each\n",
    "    encoded_frame_sequence = TimeDistributed(Frame_model)(video_input) # Run frame_model on each frame\n",
    "\n",
    "    # Add LSTM                  \n",
    "    encoded_video = LSTM(256)(encoded_frame_sequence)  # the output will be a vector\n",
    "\n",
    "    # Add a linear layer for output of video model\n",
    "    output = Dense(1, activation='linear')(encoded_video)\n",
    "\n",
    "    # Configure video_model\n",
    "    video_model = Model(inputs=video_input, outputs=output)   \n",
    "    \n",
    "    video_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 4377.7109 - mean_absolute_error: 65.4430 - val_loss: 4817.6270 - val_mean_absolute_error: 68.5856\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4817.62695, saving model to ./cnn_checkpoints_gdicnn/weights-01.hdf5\n",
      "Epoch 2/100\n",
      "59/59 [==============================] - 5s 86ms/step - loss: 3862.6616 - mean_absolute_error: 61.3387 - val_loss: 4349.4399 - val_mean_absolute_error: 65.0796\n",
      "\n",
      "Epoch 00002: val_loss improved from 4817.62695 to 4349.43994, saving model to ./cnn_checkpoints_gdicnn/weights-02.hdf5\n",
      "Epoch 3/100\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 3460.5017 - mean_absolute_error: 58.0173 - val_loss: 4038.0393 - val_mean_absolute_error: 62.6546\n",
      "\n",
      "Epoch 00003: val_loss improved from 4349.43994 to 4038.03931, saving model to ./cnn_checkpoints_gdicnn/weights-03.hdf5\n",
      "Epoch 4/100\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 3199.1970 - mean_absolute_error: 55.7182 - val_loss: 3798.2246 - val_mean_absolute_error: 60.7115\n",
      "\n",
      "Epoch 00004: val_loss improved from 4038.03931 to 3798.22461, saving model to ./cnn_checkpoints_gdicnn/weights-04.hdf5\n",
      "Epoch 5/100\n",
      "59/59 [==============================] - 6s 95ms/step - loss: 3013.9966 - mean_absolute_error: 53.9967 - val_loss: 3619.8953 - val_mean_absolute_error: 59.2251\n",
      "\n",
      "Epoch 00005: val_loss improved from 3798.22461 to 3619.89526, saving model to ./cnn_checkpoints_gdicnn/weights-05.hdf5\n",
      "Epoch 6/100\n",
      "59/59 [==============================] - 5s 84ms/step - loss: 2861.5933 - mean_absolute_error: 52.5827 - val_loss: 3467.4187 - val_mean_absolute_error: 57.9233\n",
      "\n",
      "Epoch 00006: val_loss improved from 3619.89526 to 3467.41870, saving model to ./cnn_checkpoints_gdicnn/weights-06.hdf5\n",
      "Epoch 7/100\n",
      "59/59 [==============================] - 5s 90ms/step - loss: 2728.5783 - mean_absolute_error: 51.2999 - val_loss: 3328.1094 - val_mean_absolute_error: 56.7081\n",
      "\n",
      "Epoch 00007: val_loss improved from 3467.41870 to 3328.10938, saving model to ./cnn_checkpoints_gdicnn/weights-07.hdf5\n",
      "Epoch 8/100\n",
      "59/59 [==============================] - 5s 90ms/step - loss: 2608.1553 - mean_absolute_error: 50.1101 - val_loss: 3195.7073 - val_mean_absolute_error: 55.5284\n",
      "\n",
      "Epoch 00008: val_loss improved from 3328.10938 to 3195.70728, saving model to ./cnn_checkpoints_gdicnn/weights-08.hdf5\n",
      "Epoch 9/100\n",
      "59/59 [==============================] - 5s 82ms/step - loss: 2492.2297 - mean_absolute_error: 48.9445 - val_loss: 3070.7864 - val_mean_absolute_error: 54.3917\n",
      "\n",
      "Epoch 00009: val_loss improved from 3195.70728 to 3070.78638, saving model to ./cnn_checkpoints_gdicnn/weights-09.hdf5\n",
      "Epoch 10/100\n",
      "59/59 [==============================] - 6s 96ms/step - loss: 2419.1345 - mean_absolute_error: 48.1963 - val_loss: 3070.9626 - val_mean_absolute_error: 54.3934\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3070.78638\n",
      "Epoch 11/100\n",
      "59/59 [==============================] - 5s 89ms/step - loss: 2419.2841 - mean_absolute_error: 48.1979 - val_loss: 3071.1204 - val_mean_absolute_error: 54.3948\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3070.78638\n",
      "Epoch 12/100\n",
      "59/59 [==============================] - 5s 83ms/step - loss: 2419.4155 - mean_absolute_error: 48.1992 - val_loss: 3071.2668 - val_mean_absolute_error: 54.3962\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3070.78638\n",
      "Epoch 13/100\n",
      "59/59 [==============================] - 5s 82ms/step - loss: 2419.5347 - mean_absolute_error: 48.2005 - val_loss: 3071.4021 - val_mean_absolute_error: 54.3975\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3070.78638\n",
      "Epoch 14/100\n",
      "59/59 [==============================] - 5s 82ms/step - loss: 2419.6439 - mean_absolute_error: 48.2016 - val_loss: 3071.5266 - val_mean_absolute_error: 54.3986\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3070.78638\n",
      "Epoch 15/100\n",
      "59/59 [==============================] - 5s 88ms/step - loss: 2419.7441 - mean_absolute_error: 48.2026 - val_loss: 3071.6436 - val_mean_absolute_error: 54.3997\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3070.78638\n",
      "Epoch 16/100\n",
      "59/59 [==============================] - 6s 98ms/step - loss: 2419.8401 - mean_absolute_error: 48.2037 - val_loss: 3071.7529 - val_mean_absolute_error: 54.4007\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3070.78638\n",
      "Epoch 17/100\n",
      "59/59 [==============================] - 6s 100ms/step - loss: 2419.9261 - mean_absolute_error: 48.2045 - val_loss: 3071.8594 - val_mean_absolute_error: 54.4017\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3070.78638\n",
      "Epoch 18/100\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 2420.0083 - mean_absolute_error: 48.2054 - val_loss: 3071.9597 - val_mean_absolute_error: 54.4026\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3070.78638\n",
      "Epoch 19/100\n",
      "59/59 [==============================] - 5s 83ms/step - loss: 2420.0851 - mean_absolute_error: 48.2062 - val_loss: 3072.0530 - val_mean_absolute_error: 54.4035\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3070.78638\n",
      "Epoch 20/100\n",
      "59/59 [==============================] - 5s 87ms/step - loss: 2420.1565 - mean_absolute_error: 48.2070 - val_loss: 3072.1394 - val_mean_absolute_error: 54.4043\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3070.78638\n",
      "Epoch 21/100\n",
      "59/59 [==============================] - 5s 89ms/step - loss: 2420.2260 - mean_absolute_error: 48.2077 - val_loss: 3072.2168 - val_mean_absolute_error: 54.4049\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3070.78638\n",
      "Epoch 22/100\n",
      "59/59 [==============================] - 5s 82ms/step - loss: 2420.2932 - mean_absolute_error: 48.2084 - val_loss: 3072.2898 - val_mean_absolute_error: 54.4056\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3070.78638\n",
      "Epoch 23/100\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 2420.3585 - mean_absolute_error: 48.2091 - val_loss: 3072.3594 - val_mean_absolute_error: 54.4062\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3070.78638\n",
      "Epoch 24/100\n",
      "59/59 [==============================] - 5s 86ms/step - loss: 2420.4191 - mean_absolute_error: 48.2098 - val_loss: 3072.4265 - val_mean_absolute_error: 54.4068\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3070.78638\n",
      "Epoch 25/100\n",
      "59/59 [==============================] - 5s 83ms/step - loss: 2420.4744 - mean_absolute_error: 48.2104 - val_loss: 3072.4915 - val_mean_absolute_error: 54.4074\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3070.78638\n",
      "Epoch 26/100\n",
      "59/59 [==============================] - 5s 82ms/step - loss: 2420.5294 - mean_absolute_error: 48.2110 - val_loss: 3072.5535 - val_mean_absolute_error: 54.4080\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3070.78638\n",
      "Epoch 27/100\n",
      "59/59 [==============================] - 5s 86ms/step - loss: 2420.5834 - mean_absolute_error: 48.2115 - val_loss: 3072.6091 - val_mean_absolute_error: 54.4085\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3070.78638\n",
      "Epoch 28/100\n",
      "59/59 [==============================] - 5s 83ms/step - loss: 2420.6323 - mean_absolute_error: 48.2120 - val_loss: 3072.6628 - val_mean_absolute_error: 54.4090\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3070.78638\n",
      "Epoch 29/100\n",
      "59/59 [==============================] - 5s 86ms/step - loss: 2420.6792 - mean_absolute_error: 48.2125 - val_loss: 3072.7090 - val_mean_absolute_error: 54.4094\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3070.78638\n",
      "Epoch 30/100\n",
      "59/59 [==============================] - 6s 97ms/step - loss: 2420.7266 - mean_absolute_error: 48.2130 - val_loss: 3072.7539 - val_mean_absolute_error: 54.4098\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3070.78638\n",
      "Epoch 31/100\n",
      "59/59 [==============================] - 6s 94ms/step - loss: 2420.7696 - mean_absolute_error: 48.2135 - val_loss: 3072.7971 - val_mean_absolute_error: 54.4102\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3070.78638\n",
      "Epoch 32/100\n",
      "59/59 [==============================] - 5s 88ms/step - loss: 2420.8126 - mean_absolute_error: 48.2139 - val_loss: 3072.8386 - val_mean_absolute_error: 54.4106\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3070.78638\n",
      "Epoch 33/100\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 2420.8533 - mean_absolute_error: 48.2144 - val_loss: 3072.8779 - val_mean_absolute_error: 54.4109\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3070.78638\n",
      "Epoch 34/100\n",
      "59/59 [==============================] - 5s 86ms/step - loss: 2420.8942 - mean_absolute_error: 48.2148 - val_loss: 3072.9160 - val_mean_absolute_error: 54.4113\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3070.78638\n",
      "Epoch 35/100\n",
      "59/59 [==============================] - 5s 92ms/step - loss: 2420.9341 - mean_absolute_error: 48.2152 - val_loss: 3072.9578 - val_mean_absolute_error: 54.4117\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3070.78638\n",
      "Epoch 36/100\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 2420.9765 - mean_absolute_error: 48.2157 - val_loss: 3072.9973 - val_mean_absolute_error: 54.4120\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3070.78638\n",
      "Epoch 37/100\n",
      "59/59 [==============================] - 5s 86ms/step - loss: 2421.0118 - mean_absolute_error: 48.2160 - val_loss: 3073.0371 - val_mean_absolute_error: 54.4124\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3070.78638\n",
      "Epoch 38/100\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 2421.0487 - mean_absolute_error: 48.2164 - val_loss: 3073.0742 - val_mean_absolute_error: 54.4128\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3070.78638\n",
      "Epoch 39/100\n",
      "59/59 [==============================] - 6s 97ms/step - loss: 2421.0837 - mean_absolute_error: 48.2168 - val_loss: 3073.1111 - val_mean_absolute_error: 54.4131\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3070.78638\n",
      "Epoch 40/100\n",
      "59/59 [==============================] - 6s 98ms/step - loss: 2421.1209 - mean_absolute_error: 48.2172 - val_loss: 3073.1458 - val_mean_absolute_error: 54.4134\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3070.78638\n",
      "Epoch 41/100\n",
      "59/59 [==============================] - 6s 107ms/step - loss: 2421.1519 - mean_absolute_error: 48.2175 - val_loss: 3073.1809 - val_mean_absolute_error: 54.4138\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3070.78638\n",
      "Epoch 42/100\n",
      "59/59 [==============================] - 6s 105ms/step - loss: 2421.1873 - mean_absolute_error: 48.2179 - val_loss: 3073.2146 - val_mean_absolute_error: 54.4141\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3070.78638\n",
      "Epoch 43/100\n",
      "59/59 [==============================] - 6s 99ms/step - loss: 2421.2189 - mean_absolute_error: 48.2182 - val_loss: 3073.2483 - val_mean_absolute_error: 54.4144\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3070.78638\n",
      "Epoch 44/100\n",
      "59/59 [==============================] - 6s 110ms/step - loss: 2421.2540 - mean_absolute_error: 48.2186 - val_loss: 3073.2805 - val_mean_absolute_error: 54.4147\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3070.78638\n",
      "Epoch 45/100\n",
      "59/59 [==============================] - 6s 99ms/step - loss: 2421.2870 - mean_absolute_error: 48.2189 - val_loss: 3073.3113 - val_mean_absolute_error: 54.4150\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3070.78638\n",
      "Epoch 46/100\n",
      "59/59 [==============================] - 6s 105ms/step - loss: 2421.3193 - mean_absolute_error: 48.2192 - val_loss: 3073.3416 - val_mean_absolute_error: 54.4153\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3070.78638\n",
      "Epoch 47/100\n",
      "59/59 [==============================] - 6s 105ms/step - loss: 2421.3502 - mean_absolute_error: 48.2196 - val_loss: 3073.3723 - val_mean_absolute_error: 54.4155\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3070.78638\n",
      "Epoch 48/100\n",
      "59/59 [==============================] - 7s 122ms/step - loss: 2421.3794 - mean_absolute_error: 48.2199 - val_loss: 3073.4031 - val_mean_absolute_error: 54.4158\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3070.78638\n",
      "Epoch 49/100\n",
      "59/59 [==============================] - 6s 100ms/step - loss: 2421.4074 - mean_absolute_error: 48.2202 - val_loss: 3073.4343 - val_mean_absolute_error: 54.4161\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3070.78638\n",
      "Epoch 50/100\n",
      "59/59 [==============================] - 6s 97ms/step - loss: 2421.4370 - mean_absolute_error: 48.2205 - val_loss: 3073.4648 - val_mean_absolute_error: 54.4164\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3070.78638\n",
      "Epoch 51/100\n",
      "59/59 [==============================] - 6s 105ms/step - loss: 2421.4653 - mean_absolute_error: 48.2208 - val_loss: 3073.4951 - val_mean_absolute_error: 54.4167\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3070.78638\n",
      "Epoch 52/100\n",
      "59/59 [==============================] - 6s 106ms/step - loss: 2421.4897 - mean_absolute_error: 48.2210 - val_loss: 3073.5261 - val_mean_absolute_error: 54.4169\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3070.78638\n",
      "Epoch 53/100\n",
      "59/59 [==============================] - 6s 101ms/step - loss: 2421.5211 - mean_absolute_error: 48.2213 - val_loss: 3073.5564 - val_mean_absolute_error: 54.4172\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3070.78638\n",
      "Epoch 54/100\n",
      "59/59 [==============================] - 6s 100ms/step - loss: 2421.5469 - mean_absolute_error: 48.2216 - val_loss: 3073.5850 - val_mean_absolute_error: 54.4175\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3070.78638\n",
      "Epoch 55/100\n",
      "59/59 [==============================] - 6s 94ms/step - loss: 2421.5730 - mean_absolute_error: 48.2219 - val_loss: 3073.6125 - val_mean_absolute_error: 54.4177\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3070.78638\n",
      "Epoch 56/100\n",
      "59/59 [==============================] - 6s 96ms/step - loss: 2421.5995 - mean_absolute_error: 48.2222 - val_loss: 3073.6396 - val_mean_absolute_error: 54.4180\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3070.78638\n",
      "Epoch 57/100\n",
      "59/59 [==============================] - 6s 98ms/step - loss: 2421.6235 - mean_absolute_error: 48.2224 - val_loss: 3073.6667 - val_mean_absolute_error: 54.4182\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3070.78638\n",
      "Epoch 58/100\n",
      "59/59 [==============================] - 6s 95ms/step - loss: 2421.6490 - mean_absolute_error: 48.2227 - val_loss: 3073.6926 - val_mean_absolute_error: 54.4185\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3070.78638\n",
      "Epoch 59/100\n",
      "59/59 [==============================] - 5s 91ms/step - loss: 2421.6708 - mean_absolute_error: 48.2229 - val_loss: 3073.7185 - val_mean_absolute_error: 54.4187\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3070.78638\n",
      "Epoch 60/100\n",
      "59/59 [==============================] - 6s 106ms/step - loss: 2421.6939 - mean_absolute_error: 48.2231 - val_loss: 3073.7441 - val_mean_absolute_error: 54.4189\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3070.78638\n",
      "Epoch 61/100\n",
      "59/59 [==============================] - 5s 87ms/step - loss: 2421.7190 - mean_absolute_error: 48.2234 - val_loss: 3073.7668 - val_mean_absolute_error: 54.4191\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3070.78638\n",
      "Epoch 62/100\n",
      "59/59 [==============================] - 5s 93ms/step - loss: 2421.7413 - mean_absolute_error: 48.2236 - val_loss: 3073.7898 - val_mean_absolute_error: 54.4193\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3070.78638\n",
      "Epoch 63/100\n",
      "59/59 [==============================] - 6s 107ms/step - loss: 2421.7612 - mean_absolute_error: 48.2238 - val_loss: 3073.8123 - val_mean_absolute_error: 54.4195\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3070.78638\n",
      "Epoch 64/100\n",
      "59/59 [==============================] - 5s 86ms/step - loss: 2421.7830 - mean_absolute_error: 48.2241 - val_loss: 3073.8342 - val_mean_absolute_error: 54.4197\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3070.78638\n",
      "Epoch 65/100\n",
      "59/59 [==============================] - 6s 96ms/step - loss: 2421.8068 - mean_absolute_error: 48.2243 - val_loss: 3073.8562 - val_mean_absolute_error: 54.4199\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3070.78638\n",
      "Epoch 66/100\n",
      "59/59 [==============================] - 6s 99ms/step - loss: 2421.8244 - mean_absolute_error: 48.2245 - val_loss: 3073.8787 - val_mean_absolute_error: 54.4201\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3070.78638\n",
      "Epoch 67/100\n",
      "59/59 [==============================] - 6s 98ms/step - loss: 2421.8440 - mean_absolute_error: 48.2247 - val_loss: 3073.9031 - val_mean_absolute_error: 54.4203\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 3070.78638\n",
      "Epoch 68/100\n",
      "59/59 [==============================] - 6s 100ms/step - loss: 2421.8638 - mean_absolute_error: 48.2249 - val_loss: 3073.9260 - val_mean_absolute_error: 54.4205\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 3070.78638\n",
      "Epoch 69/100\n",
      "59/59 [==============================] - 5s 92ms/step - loss: 2421.8814 - mean_absolute_error: 48.2251 - val_loss: 3073.9492 - val_mean_absolute_error: 54.4207\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 3070.78638\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 5s 91ms/step - loss: 2421.9015 - mean_absolute_error: 48.2253 - val_loss: 3073.9717 - val_mean_absolute_error: 54.4209\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 3070.78638\n",
      "Epoch 71/100\n",
      "59/59 [==============================] - 6s 107ms/step - loss: 2421.9178 - mean_absolute_error: 48.2254 - val_loss: 3073.9929 - val_mean_absolute_error: 54.4211\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 3070.78638\n",
      "Epoch 72/100\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 2421.9317 - mean_absolute_error: 48.2256 - val_loss: 3074.0149 - val_mean_absolute_error: 54.4213\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 3070.78638\n",
      "Epoch 73/100\n",
      "59/59 [==============================] - 7s 114ms/step - loss: 2421.9505 - mean_absolute_error: 48.2258 - val_loss: 3074.0364 - val_mean_absolute_error: 54.4215\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 3070.78638\n",
      "Epoch 74/100\n",
      "59/59 [==============================] - 7s 113ms/step - loss: 2421.9674 - mean_absolute_error: 48.2260 - val_loss: 3074.0569 - val_mean_absolute_error: 54.4217\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 3070.78638\n",
      "Epoch 75/100\n",
      "59/59 [==============================] - 6s 95ms/step - loss: 2421.9830 - mean_absolute_error: 48.2261 - val_loss: 3074.0781 - val_mean_absolute_error: 54.4218\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 3070.78638\n",
      "Epoch 76/100\n",
      "59/59 [==============================] - 6s 95ms/step - loss: 2421.9984 - mean_absolute_error: 48.2263 - val_loss: 3074.0986 - val_mean_absolute_error: 54.4220\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 3070.78638\n",
      "Epoch 77/100\n",
      "59/59 [==============================] - 6s 106ms/step - loss: 2422.0136 - mean_absolute_error: 48.2264 - val_loss: 3074.1194 - val_mean_absolute_error: 54.4222\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 3070.78638\n",
      "Epoch 78/100\n",
      "59/59 [==============================] - 6s 99ms/step - loss: 2422.0312 - mean_absolute_error: 48.2266 - val_loss: 3074.1409 - val_mean_absolute_error: 54.4224\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 3070.78638\n",
      "Epoch 79/100\n",
      "59/59 [==============================] - 6s 100ms/step - loss: 2422.0481 - mean_absolute_error: 48.2268 - val_loss: 3074.1611 - val_mean_absolute_error: 54.4225\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 3070.78638\n",
      "Epoch 80/100\n",
      "59/59 [==============================] - 5s 91ms/step - loss: 2422.0625 - mean_absolute_error: 48.2269 - val_loss: 3074.1797 - val_mean_absolute_error: 54.4227\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 3070.78638\n",
      "Epoch 81/100\n",
      "59/59 [==============================] - 5s 93ms/step - loss: 2422.0766 - mean_absolute_error: 48.2271 - val_loss: 3074.1982 - val_mean_absolute_error: 54.4229\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 3070.78638\n",
      "Epoch 82/100\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 2422.0895 - mean_absolute_error: 48.2272 - val_loss: 3074.2170 - val_mean_absolute_error: 54.4230\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 3070.78638\n",
      "Epoch 83/100\n",
      "59/59 [==============================] - 6s 94ms/step - loss: 2422.1016 - mean_absolute_error: 48.2273 - val_loss: 3074.2363 - val_mean_absolute_error: 54.4232\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 3070.78638\n",
      "Epoch 84/100\n",
      "59/59 [==============================] - 6s 100ms/step - loss: 2422.1170 - mean_absolute_error: 48.2275 - val_loss: 3074.2532 - val_mean_absolute_error: 54.4233\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 3070.78638\n",
      "Epoch 85/100\n",
      "59/59 [==============================] - 6s 109ms/step - loss: 2422.1268 - mean_absolute_error: 48.2276 - val_loss: 3074.2712 - val_mean_absolute_error: 54.4235\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 3070.78638\n",
      "Epoch 86/100\n",
      "59/59 [==============================] - 6s 97ms/step - loss: 2422.1396 - mean_absolute_error: 48.2277 - val_loss: 3074.2893 - val_mean_absolute_error: 54.4236\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 3070.78638\n",
      "Epoch 87/100\n",
      "59/59 [==============================] - 7s 112ms/step - loss: 2422.1551 - mean_absolute_error: 48.2279 - val_loss: 3074.3047 - val_mean_absolute_error: 54.4238\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 3070.78638\n",
      "Epoch 88/100\n",
      "59/59 [==============================] - 7s 124ms/step - loss: 2422.1637 - mean_absolute_error: 48.2280 - val_loss: 3074.3215 - val_mean_absolute_error: 54.4239\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 3070.78638\n",
      "Epoch 89/100\n",
      "59/59 [==============================] - 6s 110ms/step - loss: 2422.1743 - mean_absolute_error: 48.2281 - val_loss: 3074.3372 - val_mean_absolute_error: 54.4240\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 3070.78638\n",
      "Epoch 90/100\n",
      "59/59 [==============================] - 7s 123ms/step - loss: 2422.1855 - mean_absolute_error: 48.2282 - val_loss: 3074.3523 - val_mean_absolute_error: 54.4242\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 3070.78638\n",
      "Epoch 91/100\n",
      "59/59 [==============================] - 8s 131ms/step - loss: 2422.1954 - mean_absolute_error: 48.2283 - val_loss: 3074.3665 - val_mean_absolute_error: 54.4243\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 3070.78638\n",
      "Epoch 92/100\n",
      "59/59 [==============================] - 8s 129ms/step - loss: 2422.2061 - mean_absolute_error: 48.2284 - val_loss: 3074.3809 - val_mean_absolute_error: 54.4244\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 3070.78638\n",
      "Epoch 93/100\n",
      "59/59 [==============================] - 6s 95ms/step - loss: 2422.2184 - mean_absolute_error: 48.2286 - val_loss: 3074.3933 - val_mean_absolute_error: 54.4245\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 3070.78638\n",
      "Epoch 94/100\n",
      "59/59 [==============================] - 6s 104ms/step - loss: 2422.2251 - mean_absolute_error: 48.2286 - val_loss: 3074.4053 - val_mean_absolute_error: 54.4246\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 3070.78638\n",
      "Epoch 95/100\n",
      "59/59 [==============================] - 6s 97ms/step - loss: 2422.2359 - mean_absolute_error: 48.2287 - val_loss: 3074.4182 - val_mean_absolute_error: 54.4247\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 3070.78638\n",
      "Epoch 96/100\n",
      "59/59 [==============================] - 6s 102ms/step - loss: 2422.2443 - mean_absolute_error: 48.2288 - val_loss: 3074.4299 - val_mean_absolute_error: 54.4249\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 3070.78638\n",
      "Epoch 97/100\n",
      "59/59 [==============================] - 7s 123ms/step - loss: 2422.2549 - mean_absolute_error: 48.2289 - val_loss: 3074.4414 - val_mean_absolute_error: 54.4250\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 3070.78638\n",
      "Epoch 98/100\n",
      "59/59 [==============================] - 7s 110ms/step - loss: 2422.2627 - mean_absolute_error: 48.2290 - val_loss: 3074.4524 - val_mean_absolute_error: 54.4250\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 3070.78638\n",
      "Epoch 99/100\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 2422.2711 - mean_absolute_error: 48.2291 - val_loss: 3074.4631 - val_mean_absolute_error: 54.4251\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 3070.78638\n",
      "Epoch 100/100\n",
      "59/59 [==============================] - 6s 100ms/step - loss: 2422.2791 - mean_absolute_error: 48.2292 - val_loss: 3074.4729 - val_mean_absolute_error: 54.4252\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 3070.78638\n"
     ]
    }
   ],
   "source": [
    "if type_of_input == 'video':\n",
    "    # train_model = True\n",
    "\n",
    "    if not os.path.exists(checkpoint_folder):\n",
    "        os.makedirs(checkpoint_folder)\n",
    "\n",
    "    filepath=checkpoint_folder+\"/weights-{epoch:02d}.hdf5\"\n",
    "    # if train_model:\n",
    "\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    #opt = RMSprop(lr=0.0,rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    if type_of_input == 'video':\n",
    "        video_model.compile(loss='mse',metrics=['mae'],optimizer=opt)\n",
    "    elif type_of_input == 'video':\n",
    "        Frame_model.compile(loss='mse',metrics=['accuracy'],optimizer=opt)\n",
    "\n",
    "    #model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    checkpoint = \\\n",
    "        ModelCheckpoint(filepath, verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    lr = LearningRateScheduler(step_decay(initial_lrate,epochs_drop,drop_factor))\n",
    "\n",
    "    #  APURVA\n",
    "    # history = Frame_model.fit(train_imgs, train_labels,callbacks=[checkpoint,lr,TerminateOnNaN()],\n",
    "    #           validation_data=(validation_imgs,validation_labels),\n",
    "    #           batch_size=batch_size, epochs=epochs,shuffle=True)\n",
    "\n",
    "    # ADAM\n",
    "    # history = Frame_model.fit(train_imgs_crops_res, train_labels,callbacks=[checkpoint,lr,TerminateOnNaN()],\n",
    "    #           validation_data=(validation_imgs_crops_res,validation_labels),\n",
    "    #           batch_size=batch_size, epochs=epochs,shuffle=True)\n",
    "    history = video_model.fit(train_videos, train_videos_labels,callbacks=[checkpoint,lr,TerminateOnNaN()],\n",
    "              validation_data=(validation_videos,validation_videos_labels),\n",
    "              batch_size=batch_size, epochs=epochs,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 18\n",
    "dropout_amount = 0.1\n",
    "checkpoint_folder = \"./cnn_checkpoints_gdicnn_loss_sce\"\n",
    "reg = keras.regularizers.l2(l2_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils.np_utils import to_categorical\n",
    "# train_categorical_labels = to_categorical(train_labels, num_classes=None)\n",
    "# validation_categorical_labels = to_categorical(validation_labels, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_categorical_labels)\n",
    "# len(train_categorical_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images shape :  (311, 224, 224, 3)\n",
      "train labels shape :  (311,)\n",
      "validation images shape :  (85, 224, 224, 3)\n",
      "validation labels shape :  (85,)\n",
      "[62.14180193 62.14180193 62.14180193 62.14180193 62.14180193 62.14180193\n",
      " 62.14180193 62.14180193 62.14180193 62.14180193 62.14180193 73.25523767\n",
      " 73.25523767 73.25523767 73.25523767 73.25523767 73.25523767 73.25523767\n",
      " 73.25523767 80.44922367 80.44922367 80.44922367 80.44922367 80.44922367\n",
      " 80.44922367]\n",
      "[[  0   0   0   0   0   0   0   0   0   0 188 189 190 191 191]\n",
      " [  0   0   0   0   0   0   0   0   0   0 184 184 185 185 186]\n",
      " [  0   0   0   0   0   0   0   0   0 179 179 179 180 180 180]\n",
      " [  0   0   0   0   0   0   0   0 174 174 174 174 175 175 175]\n",
      " [  0   0   0   0   0   0   0   0 170 170 170 169 169 169 169]\n",
      " [  0   0   0   0   0   0   0   0 164 164 163 163 163 163 163]\n",
      " [  0   0   0   0   0   0   0   0 158 158 157 157 156 156 156]\n",
      " [  0   0   0   0   0   0   0   0 152 152 151 150 150 150 150]\n",
      " [  0   0   0   0   0   0   0   0 146 146 145 144 143 143 143]\n",
      " [  0   0   0   0   0   0   0   0 139 138 137 136 136 135 135]\n",
      " [  0   0   0   0   0   0   0   0 131 130 130 129 128 128 127]\n",
      " [  0   0   0   0   0   0   0   0 123 123 122 121 120 120 120]\n",
      " [  0   0   0   0   0   0   0   0   0 115 114 113 113 112 112]\n",
      " [  0   0   0   0   0   0   0   0   0   0 109 108 107 107 107]\n",
      " [  0   0   0   0   0   0   0   0   0   0 104 103 102 102 101]]\n"
     ]
    }
   ],
   "source": [
    "    print('train images shape : ',train_imgs_crops_res.shape)\n",
    "    print('train labels shape : ',train_labels.shape)\n",
    "    print('validation images shape : ',validation_imgs_crops_res.shape)\n",
    "    print('validation labels shape : ',validation_labels.shape)\n",
    "    print(train_labels[0:25])\n",
    "    print(train_imgs_crops_res[0,10:25,10:25,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 311 samples, validate on 85 samples\n",
      "Epoch 1/100\n",
      "311/311 [==============================] - 204s 656ms/step - loss: 5533.0440 - val_loss: 5374.4448\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5374.44478, saving model to ./cnn_checkpoints_gdicnn/weights-01.hdf5\n",
      "Epoch 2/100\n",
      "311/311 [==============================] - 215s 690ms/step - loss: 5209.7200 - val_loss: 5052.8941\n",
      "\n",
      "Epoch 00002: val_loss improved from 5374.44478 to 5052.89407, saving model to ./cnn_checkpoints_gdicnn/weights-02.hdf5\n",
      "Epoch 3/100\n",
      "311/311 [==============================] - 201s 647ms/step - loss: 4888.1017 - val_loss: 4730.0425\n",
      "\n",
      "Epoch 00003: val_loss improved from 5052.89407 to 4730.04249, saving model to ./cnn_checkpoints_gdicnn/weights-03.hdf5\n",
      "Epoch 4/100\n",
      "311/311 [==============================] - 202s 651ms/step - loss: 4564.4791 - val_loss: 4402.6828\n",
      "\n",
      "Epoch 00004: val_loss improved from 4730.04249 to 4402.68277, saving model to ./cnn_checkpoints_gdicnn/weights-04.hdf5\n",
      "Epoch 5/100\n",
      "311/311 [==============================] - 205s 660ms/step - loss: 4236.2495 - val_loss: 4070.0704\n",
      "\n",
      "Epoch 00005: val_loss improved from 4402.68277 to 4070.07042, saving model to ./cnn_checkpoints_gdicnn/weights-05.hdf5\n",
      "Epoch 6/100\n",
      "311/311 [==============================] - 210s 674ms/step - loss: 3902.8374 - val_loss: 3736.0630\n",
      "\n",
      "Epoch 00006: val_loss improved from 4070.07042 to 3736.06300, saving model to ./cnn_checkpoints_gdicnn/weights-06.hdf5\n",
      "Epoch 7/100\n",
      "311/311 [==============================] - 210s 676ms/step - loss: 3568.0037 - val_loss: 3398.9505\n",
      "\n",
      "Epoch 00007: val_loss improved from 3736.06300 to 3398.95048, saving model to ./cnn_checkpoints_gdicnn/weights-07.hdf5\n",
      "Epoch 8/100\n",
      "311/311 [==============================] - 209s 673ms/step - loss: 3233.4375 - val_loss: 3064.9220\n",
      "\n",
      "Epoch 00008: val_loss improved from 3398.95048 to 3064.92202, saving model to ./cnn_checkpoints_gdicnn/weights-08.hdf5\n",
      "Epoch 9/100\n",
      "311/311 [==============================] - 210s 676ms/step - loss: 2903.8845 - val_loss: 2738.9731\n",
      "\n",
      "Epoch 00009: val_loss improved from 3064.92202 to 2738.97313, saving model to ./cnn_checkpoints_gdicnn/weights-09.hdf5\n",
      "Epoch 10/100\n",
      "311/311 [==============================] - 209s 671ms/step - loss: 2614.3021 - val_loss: 2487.2515\n",
      "\n",
      "Epoch 00010: val_loss improved from 2738.97313 to 2487.25150, saving model to ./cnn_checkpoints_gdicnn/weights-10.hdf5\n",
      "Epoch 11/100\n",
      "311/311 [==============================] - 210s 675ms/step - loss: 2367.8700 - val_loss: 2244.6839\n",
      "\n",
      "Epoch 00011: val_loss improved from 2487.25150 to 2244.68386, saving model to ./cnn_checkpoints_gdicnn/weights-11.hdf5\n",
      "Epoch 12/100\n",
      "311/311 [==============================] - 212s 681ms/step - loss: 2131.7801 - val_loss: 2015.1951\n",
      "\n",
      "Epoch 00012: val_loss improved from 2244.68386 to 2015.19511, saving model to ./cnn_checkpoints_gdicnn/weights-12.hdf5\n",
      "Epoch 13/100\n",
      "311/311 [==============================] - 212s 683ms/step - loss: 1908.9857 - val_loss: 1798.2095\n",
      "\n",
      "Epoch 00013: val_loss improved from 2015.19511 to 1798.20949, saving model to ./cnn_checkpoints_gdicnn/weights-13.hdf5\n",
      "Epoch 14/100\n",
      "311/311 [==============================] - 213s 684ms/step - loss: 1699.9641 - val_loss: 1595.0955\n",
      "\n",
      "Epoch 00014: val_loss improved from 1798.20949 to 1595.09545, saving model to ./cnn_checkpoints_gdicnn/weights-14.hdf5\n",
      "Epoch 15/100\n",
      "311/311 [==============================] - 213s 684ms/step - loss: 1506.2654 - val_loss: 1406.6227\n",
      "\n",
      "Epoch 00015: val_loss improved from 1595.09545 to 1406.62273, saving model to ./cnn_checkpoints_gdicnn/weights-15.hdf5\n",
      "Epoch 16/100\n",
      "311/311 [==============================] - 213s 686ms/step - loss: 1326.4972 - val_loss: 1237.9422\n",
      "\n",
      "Epoch 00016: val_loss improved from 1406.62273 to 1237.94218, saving model to ./cnn_checkpoints_gdicnn/weights-16.hdf5\n",
      "Epoch 17/100\n",
      "311/311 [==============================] - 212s 682ms/step - loss: 1163.8519 - val_loss: 1082.6218\n",
      "\n",
      "Epoch 00017: val_loss improved from 1237.94218 to 1082.62176, saving model to ./cnn_checkpoints_gdicnn/weights-17.hdf5\n",
      "Epoch 18/100\n",
      "311/311 [==============================] - 213s 683ms/step - loss: 1016.3726 - val_loss: 942.1214\n",
      "\n",
      "Epoch 00018: val_loss improved from 1082.62176 to 942.12140, saving model to ./cnn_checkpoints_gdicnn/weights-18.hdf5\n",
      "Epoch 19/100\n",
      "311/311 [==============================] - 215s 692ms/step - loss: 884.2303 - val_loss: 815.8372\n",
      "\n",
      "Epoch 00019: val_loss improved from 942.12140 to 815.83724, saving model to ./cnn_checkpoints_gdicnn/weights-19.hdf5\n",
      "Epoch 20/100\n",
      "311/311 [==============================] - 212s 682ms/step - loss: 776.8286 - val_loss: 726.9758\n",
      "\n",
      "Epoch 00020: val_loss improved from 815.83724 to 726.97578, saving model to ./cnn_checkpoints_gdicnn/weights-20.hdf5\n",
      "Epoch 21/100\n",
      "311/311 [==============================] - 213s 684ms/step - loss: 692.0351 - val_loss: 645.5235\n",
      "\n",
      "Epoch 00021: val_loss improved from 726.97578 to 645.52354, saving model to ./cnn_checkpoints_gdicnn/weights-21.hdf5\n",
      "Epoch 22/100\n",
      "311/311 [==============================] - 213s 684ms/step - loss: 615.0444 - val_loss: 572.9326\n",
      "\n",
      "Epoch 00022: val_loss improved from 645.52354 to 572.93261, saving model to ./cnn_checkpoints_gdicnn/weights-22.hdf5\n",
      "Epoch 23/100\n",
      "311/311 [==============================] - 213s 684ms/step - loss: 546.5973 - val_loss: 506.1908\n",
      "\n",
      "Epoch 00023: val_loss improved from 572.93261 to 506.19084, saving model to ./cnn_checkpoints_gdicnn/weights-23.hdf5\n",
      "Epoch 24/100\n",
      "311/311 [==============================] - 213s 684ms/step - loss: 484.6233 - val_loss: 448.8711\n",
      "\n",
      "Epoch 00024: val_loss improved from 506.19084 to 448.87110, saving model to ./cnn_checkpoints_gdicnn/weights-24.hdf5\n",
      "Epoch 25/100\n",
      "311/311 [==============================] - 213s 684ms/step - loss: 430.1216 - val_loss: 397.6144\n",
      "\n",
      "Epoch 00025: val_loss improved from 448.87110 to 397.61439, saving model to ./cnn_checkpoints_gdicnn/weights-25.hdf5\n",
      "Epoch 26/100\n",
      "311/311 [==============================] - 213s 686ms/step - loss: 382.0099 - val_loss: 352.2620\n",
      "\n",
      "Epoch 00026: val_loss improved from 397.61439 to 352.26201, saving model to ./cnn_checkpoints_gdicnn/weights-26.hdf5\n",
      "Epoch 27/100\n",
      "311/311 [==============================] - 214s 689ms/step - loss: 339.9199 - val_loss: 311.9187\n",
      "\n",
      "Epoch 00027: val_loss improved from 352.26201 to 311.91873, saving model to ./cnn_checkpoints_gdicnn/weights-27.hdf5\n",
      "Epoch 28/100\n",
      "311/311 [==============================] - 214s 688ms/step - loss: 302.9151 - val_loss: 277.3330\n",
      "\n",
      "Epoch 00028: val_loss improved from 311.91873 to 277.33303, saving model to ./cnn_checkpoints_gdicnn/weights-28.hdf5\n",
      "Epoch 29/100\n",
      "311/311 [==============================] - 212s 681ms/step - loss: 270.8480 - val_loss: 247.7190\n",
      "\n",
      "Epoch 00029: val_loss improved from 277.33303 to 247.71899, saving model to ./cnn_checkpoints_gdicnn/weights-29.hdf5\n",
      "Epoch 30/100\n",
      "311/311 [==============================] - 210s 676ms/step - loss: 245.8156 - val_loss: 226.8092\n",
      "\n",
      "Epoch 00030: val_loss improved from 247.71899 to 226.80921, saving model to ./cnn_checkpoints_gdicnn/weights-30.hdf5\n",
      "Epoch 31/100\n",
      "311/311 [==============================] - 219s 705ms/step - loss: 226.3283 - val_loss: 208.1602\n",
      "\n",
      "Epoch 00031: val_loss improved from 226.80921 to 208.16022, saving model to ./cnn_checkpoints_gdicnn/weights-31.hdf5\n",
      "Epoch 32/100\n",
      "311/311 [==============================] - 210s 676ms/step - loss: 209.0383 - val_loss: 191.7601\n",
      "\n",
      "Epoch 00032: val_loss improved from 208.16022 to 191.76006, saving model to ./cnn_checkpoints_gdicnn/weights-32.hdf5\n",
      "Epoch 33/100\n",
      "311/311 [==============================] - 208s 670ms/step - loss: 193.8817 - val_loss: 177.2786\n",
      "\n",
      "Epoch 00033: val_loss improved from 191.76006 to 177.27863, saving model to ./cnn_checkpoints_gdicnn/weights-33.hdf5\n",
      "Epoch 34/100\n",
      "311/311 [==============================] - 210s 675ms/step - loss: 180.4078 - val_loss: 164.9456\n",
      "\n",
      "Epoch 00034: val_loss improved from 177.27863 to 164.94556, saving model to ./cnn_checkpoints_gdicnn/weights-34.hdf5\n",
      "Epoch 35/100\n",
      "311/311 [==============================] - 211s 679ms/step - loss: 168.9550 - val_loss: 153.5019\n",
      "\n",
      "Epoch 00035: val_loss improved from 164.94556 to 153.50186, saving model to ./cnn_checkpoints_gdicnn/weights-35.hdf5\n",
      "Epoch 36/100\n",
      "311/311 [==============================] - 210s 674ms/step - loss: 158.7153 - val_loss: 144.2253\n",
      "\n",
      "Epoch 00036: val_loss improved from 153.50186 to 144.22531, saving model to ./cnn_checkpoints_gdicnn/weights-36.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "311/311 [==============================] - 209s 671ms/step - loss: 150.0710 - val_loss: 135.9316\n",
      "\n",
      "Epoch 00037: val_loss improved from 144.22531 to 135.93158, saving model to ./cnn_checkpoints_gdicnn/weights-37.hdf5\n",
      "Epoch 38/100\n",
      "311/311 [==============================] - 209s 672ms/step - loss: 142.5935 - val_loss: 128.8020\n",
      "\n",
      "Epoch 00038: val_loss improved from 135.93158 to 128.80204, saving model to ./cnn_checkpoints_gdicnn/weights-38.hdf5\n",
      "Epoch 39/100\n",
      "311/311 [==============================] - 210s 675ms/step - loss: 136.1913 - val_loss: 122.7038\n",
      "\n",
      "Epoch 00039: val_loss improved from 128.80204 to 122.70380, saving model to ./cnn_checkpoints_gdicnn/weights-39.hdf5\n",
      "Epoch 40/100\n",
      "311/311 [==============================] - 209s 672ms/step - loss: 131.0446 - val_loss: 118.8674\n",
      "\n",
      "Epoch 00040: val_loss improved from 122.70380 to 118.86738, saving model to ./cnn_checkpoints_gdicnn/weights-40.hdf5\n",
      "Epoch 41/100\n",
      "311/311 [==============================] - 209s 673ms/step - loss: 127.3390 - val_loss: 115.0173\n",
      "\n",
      "Epoch 00041: val_loss improved from 118.86738 to 115.01731, saving model to ./cnn_checkpoints_gdicnn/weights-41.hdf5\n",
      "Epoch 42/100\n",
      "311/311 [==============================] - 207s 665ms/step - loss: 123.8730 - val_loss: 111.9625\n",
      "\n",
      "Epoch 00042: val_loss improved from 115.01731 to 111.96251, saving model to ./cnn_checkpoints_gdicnn/weights-42.hdf5\n",
      "Epoch 43/100\n",
      "311/311 [==============================] - 209s 673ms/step - loss: 121.0158 - val_loss: 108.9535\n",
      "\n",
      "Epoch 00043: val_loss improved from 111.96251 to 108.95348, saving model to ./cnn_checkpoints_gdicnn/weights-43.hdf5\n",
      "Epoch 44/100\n",
      "311/311 [==============================] - 207s 664ms/step - loss: 118.3746 - val_loss: 106.5590\n",
      "\n",
      "Epoch 00044: val_loss improved from 108.95348 to 106.55902, saving model to ./cnn_checkpoints_gdicnn/weights-44.hdf5\n",
      "Epoch 45/100\n",
      "311/311 [==============================] - 208s 668ms/step - loss: 116.1435 - val_loss: 104.3844\n",
      "\n",
      "Epoch 00045: val_loss improved from 106.55902 to 104.38444, saving model to ./cnn_checkpoints_gdicnn/weights-45.hdf5\n",
      "Epoch 46/100\n",
      "311/311 [==============================] - 206s 664ms/step - loss: 114.1700 - val_loss: 102.6898\n",
      "\n",
      "Epoch 00046: val_loss improved from 104.38444 to 102.68985, saving model to ./cnn_checkpoints_gdicnn/weights-46.hdf5\n",
      "Epoch 47/100\n",
      "311/311 [==============================] - 208s 667ms/step - loss: 112.5408 - val_loss: 101.0468\n",
      "\n",
      "Epoch 00047: val_loss improved from 102.68985 to 101.04678, saving model to ./cnn_checkpoints_gdicnn/weights-47.hdf5\n",
      "Epoch 48/100\n",
      "311/311 [==============================] - 206s 663ms/step - loss: 111.0809 - val_loss: 99.5770\n",
      "\n",
      "Epoch 00048: val_loss improved from 101.04678 to 99.57704, saving model to ./cnn_checkpoints_gdicnn/weights-48.hdf5\n",
      "Epoch 49/100\n",
      "311/311 [==============================] - 208s 667ms/step - loss: 109.8095 - val_loss: 98.4575\n",
      "\n",
      "Epoch 00049: val_loss improved from 99.57704 to 98.45753, saving model to ./cnn_checkpoints_gdicnn/weights-49.hdf5\n",
      "Epoch 50/100\n",
      "311/311 [==============================] - 207s 665ms/step - loss: 108.9069 - val_loss: 97.5472\n",
      "\n",
      "Epoch 00050: val_loss improved from 98.45753 to 97.54718, saving model to ./cnn_checkpoints_gdicnn/weights-50.hdf5\n",
      "Epoch 51/100\n",
      "311/311 [==============================] - 208s 668ms/step - loss: 108.0995 - val_loss: 96.8879\n",
      "\n",
      "Epoch 00051: val_loss improved from 97.54718 to 96.88788, saving model to ./cnn_checkpoints_gdicnn/weights-51.hdf5\n",
      "Epoch 52/100\n",
      "311/311 [==============================] - 208s 668ms/step - loss: 107.4555 - val_loss: 96.2490\n",
      "\n",
      "Epoch 00052: val_loss improved from 96.88788 to 96.24904, saving model to ./cnn_checkpoints_gdicnn/weights-52.hdf5\n",
      "Epoch 53/100\n",
      "311/311 [==============================] - 207s 666ms/step - loss: 106.8891 - val_loss: 95.6426\n",
      "\n",
      "Epoch 00053: val_loss improved from 96.24904 to 95.64259, saving model to ./cnn_checkpoints_gdicnn/weights-53.hdf5\n",
      "Epoch 54/100\n",
      "311/311 [==============================] - 208s 669ms/step - loss: 106.3500 - val_loss: 95.1994\n",
      "\n",
      "Epoch 00054: val_loss improved from 95.64259 to 95.19939, saving model to ./cnn_checkpoints_gdicnn/weights-54.hdf5\n",
      "Epoch 55/100\n",
      "311/311 [==============================] - 206s 662ms/step - loss: 105.9460 - val_loss: 94.6745\n",
      "\n",
      "Epoch 00055: val_loss improved from 95.19939 to 94.67446, saving model to ./cnn_checkpoints_gdicnn/weights-55.hdf5\n",
      "Epoch 56/100\n",
      "311/311 [==============================] - 207s 666ms/step - loss: 105.4922 - val_loss: 94.3360\n",
      "\n",
      "Epoch 00056: val_loss improved from 94.67446 to 94.33598, saving model to ./cnn_checkpoints_gdicnn/weights-56.hdf5\n",
      "Epoch 57/100\n",
      "311/311 [==============================] - 218s 702ms/step - loss: 105.1446 - val_loss: 94.0159\n",
      "\n",
      "Epoch 00057: val_loss improved from 94.33598 to 94.01588, saving model to ./cnn_checkpoints_gdicnn/weights-57.hdf5\n",
      "Epoch 58/100\n",
      "311/311 [==============================] - 207s 665ms/step - loss: 104.8305 - val_loss: 93.7310\n",
      "\n",
      "Epoch 00058: val_loss improved from 94.01588 to 93.73099, saving model to ./cnn_checkpoints_gdicnn/weights-58.hdf5\n",
      "Epoch 59/100\n",
      "311/311 [==============================] - 206s 661ms/step - loss: 104.5597 - val_loss: 93.4521\n",
      "\n",
      "Epoch 00059: val_loss improved from 93.73099 to 93.45215, saving model to ./cnn_checkpoints_gdicnn/weights-59.hdf5\n",
      "Epoch 60/100\n",
      "311/311 [==============================] - 208s 667ms/step - loss: 104.3570 - val_loss: 93.2027\n",
      "\n",
      "Epoch 00060: val_loss improved from 93.45215 to 93.20267, saving model to ./cnn_checkpoints_gdicnn/weights-60.hdf5\n",
      "Epoch 61/100\n",
      "311/311 [==============================] - 205s 661ms/step - loss: 104.1390 - val_loss: 93.0592\n",
      "\n",
      "Epoch 00061: val_loss improved from 93.20267 to 93.05920, saving model to ./cnn_checkpoints_gdicnn/weights-61.hdf5\n",
      "Epoch 62/100\n",
      "311/311 [==============================] - 206s 662ms/step - loss: 103.9968 - val_loss: 92.8940\n",
      "\n",
      "Epoch 00062: val_loss improved from 93.05920 to 92.89402, saving model to ./cnn_checkpoints_gdicnn/weights-62.hdf5\n",
      "Epoch 63/100\n",
      "311/311 [==============================] - 206s 663ms/step - loss: 103.8349 - val_loss: 92.7466\n",
      "\n",
      "Epoch 00063: val_loss improved from 92.89402 to 92.74660, saving model to ./cnn_checkpoints_gdicnn/weights-63.hdf5\n",
      "Epoch 64/100\n",
      "311/311 [==============================] - 206s 661ms/step - loss: 103.6844 - val_loss: 92.6341\n",
      "\n",
      "Epoch 00064: val_loss improved from 92.74660 to 92.63407, saving model to ./cnn_checkpoints_gdicnn/weights-64.hdf5\n",
      "Epoch 65/100\n",
      "311/311 [==============================] - 207s 667ms/step - loss: 103.5828 - val_loss: 92.5615\n",
      "\n",
      "Epoch 00065: val_loss improved from 92.63407 to 92.56145, saving model to ./cnn_checkpoints_gdicnn/weights-65.hdf5\n",
      "Epoch 66/100\n",
      "311/311 [==============================] - 208s 669ms/step - loss: 103.4261 - val_loss: 92.4068\n",
      "\n",
      "Epoch 00066: val_loss improved from 92.56145 to 92.40683, saving model to ./cnn_checkpoints_gdicnn/weights-66.hdf5\n",
      "Epoch 67/100\n",
      "311/311 [==============================] - 207s 667ms/step - loss: 103.3257 - val_loss: 92.2771\n",
      "\n",
      "Epoch 00067: val_loss improved from 92.40683 to 92.27705, saving model to ./cnn_checkpoints_gdicnn/weights-67.hdf5\n",
      "Epoch 68/100\n",
      "311/311 [==============================] - 209s 672ms/step - loss: 103.2275 - val_loss: 92.1680\n",
      "\n",
      "Epoch 00068: val_loss improved from 92.27705 to 92.16798, saving model to ./cnn_checkpoints_gdicnn/weights-68.hdf5\n",
      "Epoch 69/100\n",
      "311/311 [==============================] - 289s 931ms/step - loss: 103.1071 - val_loss: 92.0905\n",
      "\n",
      "Epoch 00069: val_loss improved from 92.16798 to 92.09048, saving model to ./cnn_checkpoints_gdicnn/weights-69.hdf5\n",
      "Epoch 70/100\n",
      "311/311 [==============================] - 267s 859ms/step - loss: 103.0059 - val_loss: 92.0226\n",
      "\n",
      "Epoch 00070: val_loss improved from 92.09048 to 92.02264, saving model to ./cnn_checkpoints_gdicnn/weights-70.hdf5\n",
      "Epoch 71/100\n",
      "311/311 [==============================] - 264s 850ms/step - loss: 102.9364 - val_loss: 91.9392\n",
      "\n",
      "Epoch 00071: val_loss improved from 92.02264 to 91.93923, saving model to ./cnn_checkpoints_gdicnn/weights-71.hdf5\n",
      "Epoch 72/100\n",
      "311/311 [==============================] - 260s 835ms/step - loss: 102.8611 - val_loss: 91.8769\n",
      "\n",
      "Epoch 00072: val_loss improved from 91.93923 to 91.87687, saving model to ./cnn_checkpoints_gdicnn/weights-72.hdf5\n",
      "Epoch 73/100\n",
      "311/311 [==============================] - 257s 827ms/step - loss: 102.8007 - val_loss: 91.8211\n",
      "\n",
      "Epoch 00073: val_loss improved from 91.87687 to 91.82108, saving model to ./cnn_checkpoints_gdicnn/weights-73.hdf5\n",
      "Epoch 74/100\n",
      "311/311 [==============================] - 259s 833ms/step - loss: 102.7203 - val_loss: 91.7588\n",
      "\n",
      "Epoch 00074: val_loss improved from 91.82108 to 91.75880, saving model to ./cnn_checkpoints_gdicnn/weights-74.hdf5\n",
      "Epoch 75/100\n",
      "311/311 [==============================] - 262s 841ms/step - loss: 102.6604 - val_loss: 91.6845\n",
      "\n",
      "Epoch 00075: val_loss improved from 91.75880 to 91.68447, saving model to ./cnn_checkpoints_gdicnn/weights-75.hdf5\n",
      "Epoch 76/100\n",
      "311/311 [==============================] - 260s 835ms/step - loss: 102.5751 - val_loss: 91.6394\n",
      "\n",
      "Epoch 00076: val_loss improved from 91.68447 to 91.63943, saving model to ./cnn_checkpoints_gdicnn/weights-76.hdf5\n",
      "Epoch 77/100\n",
      "311/311 [==============================] - 257s 828ms/step - loss: 102.5105 - val_loss: 91.5888\n",
      "\n",
      "Epoch 00077: val_loss improved from 91.63943 to 91.58880, saving model to ./cnn_checkpoints_gdicnn/weights-77.hdf5\n",
      "Epoch 78/100\n",
      "311/311 [==============================] - 260s 837ms/step - loss: 102.4595 - val_loss: 91.5312\n",
      "\n",
      "Epoch 00078: val_loss improved from 91.58880 to 91.53125, saving model to ./cnn_checkpoints_gdicnn/weights-78.hdf5\n",
      "Epoch 79/100\n",
      "311/311 [==============================] - 260s 837ms/step - loss: 102.3990 - val_loss: 91.4652\n",
      "\n",
      "Epoch 00079: val_loss improved from 91.53125 to 91.46523, saving model to ./cnn_checkpoints_gdicnn/weights-79.hdf5\n",
      "Epoch 80/100\n",
      "311/311 [==============================] - 260s 835ms/step - loss: 102.3241 - val_loss: 91.4287\n",
      "\n",
      "Epoch 00080: val_loss improved from 91.46523 to 91.42875, saving model to ./cnn_checkpoints_gdicnn/weights-80.hdf5\n",
      "Epoch 81/100\n",
      "311/311 [==============================] - 285s 918ms/step - loss: 102.2656 - val_loss: 91.3841\n",
      "\n",
      "Epoch 00081: val_loss improved from 91.42875 to 91.38409, saving model to ./cnn_checkpoints_gdicnn/weights-81.hdf5\n",
      "Epoch 82/100\n",
      "311/311 [==============================] - 11671s 38s/step - loss: 102.2238 - val_loss: 91.3421\n",
      "\n",
      "Epoch 00082: val_loss improved from 91.38409 to 91.34209, saving model to ./cnn_checkpoints_gdicnn/weights-82.hdf5\n",
      "Epoch 83/100\n",
      "311/311 [==============================] - 184s 591ms/step - loss: 102.1924 - val_loss: 91.2886\n",
      "\n",
      "Epoch 00083: val_loss improved from 91.34209 to 91.28862, saving model to ./cnn_checkpoints_gdicnn/weights-83.hdf5\n",
      "Epoch 84/100\n",
      "311/311 [==============================] - 187s 601ms/step - loss: 102.1183 - val_loss: 91.2542\n",
      "\n",
      "Epoch 00084: val_loss improved from 91.28862 to 91.25419, saving model to ./cnn_checkpoints_gdicnn/weights-84.hdf5\n",
      "Epoch 85/100\n",
      "311/311 [==============================] - 243s 781ms/step - loss: 102.0624 - val_loss: 91.2116\n",
      "\n",
      "Epoch 00085: val_loss improved from 91.25419 to 91.21158, saving model to ./cnn_checkpoints_gdicnn/weights-85.hdf5\n",
      "Epoch 86/100\n",
      "311/311 [==============================] - 351s 1s/step - loss: 102.0186 - val_loss: 91.1760\n",
      "\n",
      "Epoch 00086: val_loss improved from 91.21158 to 91.17598, saving model to ./cnn_checkpoints_gdicnn/weights-86.hdf5\n",
      "Epoch 87/100\n",
      "311/311 [==============================] - 353s 1s/step - loss: 101.9655 - val_loss: 91.1359\n",
      "\n",
      "Epoch 00087: val_loss improved from 91.17598 to 91.13590, saving model to ./cnn_checkpoints_gdicnn/weights-87.hdf5\n",
      "Epoch 88/100\n",
      "311/311 [==============================] - 355s 1s/step - loss: 101.9121 - val_loss: 91.0913\n",
      "\n",
      "Epoch 00088: val_loss improved from 91.13590 to 91.09130, saving model to ./cnn_checkpoints_gdicnn/weights-88.hdf5\n",
      "Epoch 89/100\n",
      "311/311 [==============================] - 353s 1s/step - loss: 101.8781 - val_loss: 91.0411\n",
      "\n",
      "Epoch 00089: val_loss improved from 91.09130 to 91.04115, saving model to ./cnn_checkpoints_gdicnn/weights-89.hdf5\n",
      "Epoch 90/100\n",
      "311/311 [==============================] - 355s 1s/step - loss: 101.8025 - val_loss: 91.0168\n",
      "\n",
      "Epoch 00090: val_loss improved from 91.04115 to 91.01680, saving model to ./cnn_checkpoints_gdicnn/weights-90.hdf5\n",
      "Epoch 91/100\n",
      "311/311 [==============================] - 353s 1s/step - loss: 101.7818 - val_loss: 90.9790\n",
      "\n",
      "Epoch 00091: val_loss improved from 91.01680 to 90.97902, saving model to ./cnn_checkpoints_gdicnn/weights-91.hdf5\n",
      "Epoch 92/100\n",
      "311/311 [==============================] - 356s 1s/step - loss: 101.7170 - val_loss: 90.9488\n",
      "\n",
      "Epoch 00092: val_loss improved from 90.97902 to 90.94877, saving model to ./cnn_checkpoints_gdicnn/weights-92.hdf5\n",
      "Epoch 93/100\n",
      "311/311 [==============================] - 354s 1s/step - loss: 101.6672 - val_loss: 90.9132\n",
      "\n",
      "Epoch 00093: val_loss improved from 90.94877 to 90.91321, saving model to ./cnn_checkpoints_gdicnn/weights-93.hdf5\n",
      "Epoch 94/100\n",
      "311/311 [==============================] - 350s 1s/step - loss: 101.6291 - val_loss: 90.8797\n",
      "\n",
      "Epoch 00094: val_loss improved from 90.91321 to 90.87973, saving model to ./cnn_checkpoints_gdicnn/weights-94.hdf5\n",
      "Epoch 95/100\n",
      "311/311 [==============================] - 353s 1s/step - loss: 101.5968 - val_loss: 90.8416\n",
      "\n",
      "Epoch 00095: val_loss improved from 90.87973 to 90.84156, saving model to ./cnn_checkpoints_gdicnn/weights-95.hdf5\n",
      "Epoch 96/100\n",
      "311/311 [==============================] - 349s 1s/step - loss: 101.5548 - val_loss: 90.8192\n",
      "\n",
      "Epoch 00096: val_loss improved from 90.84156 to 90.81925, saving model to ./cnn_checkpoints_gdicnn/weights-96.hdf5\n",
      "Epoch 97/100\n",
      "311/311 [==============================] - 335s 1s/step - loss: 101.4939 - val_loss: 90.7740\n",
      "\n",
      "Epoch 00097: val_loss improved from 90.81925 to 90.77403, saving model to ./cnn_checkpoints_gdicnn/weights-97.hdf5\n",
      "Epoch 98/100\n",
      "311/311 [==============================] - 339s 1s/step - loss: 101.4508 - val_loss: 90.7406\n",
      "\n",
      "Epoch 00098: val_loss improved from 90.77403 to 90.74056, saving model to ./cnn_checkpoints_gdicnn/weights-98.hdf5\n",
      "Epoch 99/100\n",
      "311/311 [==============================] - 344s 1s/step - loss: 101.4166 - val_loss: 90.7049\n",
      "\n",
      "Epoch 00099: val_loss improved from 90.74056 to 90.70494, saving model to ./cnn_checkpoints_gdicnn/weights-99.hdf5\n",
      "Epoch 100/100\n",
      "311/311 [==============================] - 354s 1s/step - loss: 101.3639 - val_loss: 90.6774\n",
      "\n",
      "Epoch 00100: val_loss improved from 90.70494 to 90.67744, saving model to ./cnn_checkpoints_gdicnn/weights-100.hdf5\n"
     ]
    }
   ],
   "source": [
    "train_model = True\n",
    "\n",
    "if not os.path.exists(checkpoint_folder):\n",
    "    os.makedirs(checkpoint_folder)\n",
    "\n",
    "filepath=checkpoint_folder+\"/weights-{epoch:02d}.hdf5\"\n",
    "if train_model:\n",
    "\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    #opt = RMSprop(lr=0.0,rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    #model.compile(loss=keras.losses.sparse_categorical_crossentropy,metrics=['accuracy'],optimizer=opt)\n",
    "    #model.compile(loss=keras.losses.categorical_crossentropy,metrics=['accuracy'],optimizer=opt)\n",
    "    Frame_model.compile(loss='mse', optimizer=opt)\n",
    "\n",
    "\n",
    "    checkpoint = \\\n",
    "        ModelCheckpoint(filepath, verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    lr = LearningRateScheduler(step_decay(initial_lrate,epochs_drop,drop_factor))\n",
    "\n",
    "#     history = model.fit(train_imgs, train_categorical_labels,callbacks=[checkpoint,lr,TerminateOnNaN()],\n",
    "#               validation_data=(validation_imgs,validation_categorical_labels),\n",
    "#               batch_size=batch_size, epochs=epochs,shuffle=True)\n",
    "    history = Frame_model.fit(train_imgs_crops_res, train_labels,callbacks=[checkpoint,lr,TerminateOnNaN()],\n",
    "                validation_data=(validation_imgs_crops_res,validation_labels),\n",
    "                batch_size=8, epochs=100,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train on 311 samples, validate on 85 samples\n",
      "Epoch 1/50\n",
      "311/311 [==============================] - 2s 8ms/step - loss: 223.0776 - acc: 0.0000e+00 - val_loss: 122.0249 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 122.02488, saving model to ./cnn_checkpoints_gdicnn/weights-01.hdf5\n",
      "Epoch 2/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 60.7833 - acc: 0.0000e+00 - val_loss: 57.5159 - val_acc: 0.0000e+00oss: 61.5926 - acc: 0.0000e+\n",
      "\n",
      "Epoch 00002: val_loss improved from 122.02488 to 57.51592, saving model to ./cnn_checkpoints_gdicnn/weights-02.hdf5\n",
      "Epoch 3/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 27.9744 - acc: 0.0000e+00 - val_loss: 42.1295 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 57.51592 to 42.12954, saving model to ./cnn_checkpoints_gdicnn/weights-03.hdf5\n",
      "Epoch 4/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 16.0859 - acc: 0.0000e+00 - val_loss: 51.2305 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 42.12954\n",
      "Epoch 5/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 13.9234 - acc: 0.0000e+00 - val_loss: 42.0741 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss improved from 42.12954 to 42.07406, saving model to ./cnn_checkpoints_gdicnn/weights-05.hdf5\n",
      "Epoch 6/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 14.6637 - acc: 0.0000e+00 - val_loss: 35.1733 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss improved from 42.07406 to 35.17335, saving model to ./cnn_checkpoints_gdicnn/weights-06.hdf5\n",
      "Epoch 7/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 9.3281 - acc: 0.0000e+00 - val_loss: 31.6813 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss improved from 35.17335 to 31.68130, saving model to ./cnn_checkpoints_gdicnn/weights-07.hdf5\n",
      "Epoch 8/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 9.2124 - acc: 0.0000e+00 - val_loss: 30.9437 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss improved from 31.68130 to 30.94367, saving model to ./cnn_checkpoints_gdicnn/weights-08.hdf5\n",
      "Epoch 9/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 5.3239 - acc: 0.0000e+00 - val_loss: 29.6538 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss improved from 30.94367 to 29.65379, saving model to ./cnn_checkpoints_gdicnn/weights-09.hdf5\n",
      "Epoch 10/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 8.8533 - acc: 0.0000e+00 - val_loss: 42.7121 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 29.65379\n",
      "Epoch 11/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 8.7829 - acc: 0.0000e+00 - val_loss: 31.4504 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 29.65379\n",
      "Epoch 12/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 4.8136 - acc: 0.0000e+00 - val_loss: 29.3756 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss improved from 29.65379 to 29.37563, saving model to ./cnn_checkpoints_gdicnn/weights-12.hdf5\n",
      "Epoch 13/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 2.4139 - acc: 0.0000e+00 - val_loss: 27.5046 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss improved from 29.37563 to 27.50463, saving model to ./cnn_checkpoints_gdicnn/weights-13.hdf5\n",
      "Epoch 14/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 3.1617 - acc: 0.0000e+00 - val_loss: 28.1312 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 27.50463\n",
      "Epoch 15/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 1.7211 - acc: 0.0000e+00 - val_loss: 29.4977 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 27.50463\n",
      "Epoch 16/50\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 2.9882 - acc: 0.0000e+00 - val_loss: 29.0403 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 27.50463\n",
      "Epoch 17/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 1.9301 - acc: 0.0000e+00 - val_loss: 29.9213 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 27.50463\n",
      "Epoch 18/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 3.3959 - acc: 0.0000e+00 - val_loss: 28.9842 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 27.50463\n",
      "Epoch 19/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 2.2930 - acc: 0.0000e+00 - val_loss: 28.5146 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 27.50463\n",
      "Epoch 20/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 2.1052 - acc: 0.0000e+00 - val_loss: 33.5601 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 27.50463\n",
      "Epoch 21/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 1.3095 - acc: 0.0000e+00 - val_loss: 31.3402 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 27.50463\n",
      "Epoch 22/50\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 2.5693 - acc: 0.0000e+00 - val_loss: 31.1567 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 27.50463\n",
      "Epoch 23/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 1.8692 - acc: 0.0000e+00 - val_loss: 27.1204 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss improved from 27.50463 to 27.12040, saving model to ./cnn_checkpoints_gdicnn/weights-23.hdf5\n",
      "Epoch 24/50\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.8816 - acc: 0.0000e+00 - val_loss: 34.8326 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 27.12040\n",
      "Epoch 25/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 1.7645 - acc: 0.0000e+00 - val_loss: 27.7227 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 27.12040\n",
      "Epoch 26/50\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 2.1977 - acc: 0.0000e+00 - val_loss: 28.5260 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 27.12040\n",
      "Epoch 27/50\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.8084 - acc: 0.0000e+00 - val_loss: 28.1097 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 27.12040\n",
      "Epoch 28/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 1.2620 - acc: 0.0000e+00 - val_loss: 30.4594 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 27.12040\n",
      "Epoch 29/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 1.4037 - acc: 0.0000e+00 - val_loss: 28.3519 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 27.12040\n",
      "Epoch 30/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 1.0026 - acc: 0.0000e+00 - val_loss: 29.9990 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 27.12040\n",
      "Epoch 31/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 1.1108 - acc: 0.0000e+00 - val_loss: 29.1093 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 27.12040\n",
      "Epoch 32/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 1.0682 - acc: 0.0000e+00 - val_loss: 27.8035 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 27.12040\n",
      "Epoch 33/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 0.9115 - acc: 0.0000e+00 - val_loss: 28.1523 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 27.12040\n",
      "Epoch 34/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 1.2417 - acc: 0.0000e+00 - val_loss: 29.9052 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 27.12040\n",
      "Epoch 35/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 0.9423 - acc: 0.0000e+00 - val_loss: 26.3570 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_loss improved from 27.12040 to 26.35696, saving model to ./cnn_checkpoints_gdicnn/weights-35.hdf5\n",
      "Epoch 36/50\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.5623 - acc: 0.0000e+00 - val_loss: 27.8472 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 26.35696\n",
      "Epoch 37/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 0.9448 - acc: 0.0000e+00 - val_loss: 27.4707 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 26.35696\n",
      "Epoch 38/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 1.0335 - acc: 0.0000e+00 - val_loss: 28.0968 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 26.35696\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 [==============================] - 1s 5ms/step - loss: 1.4257 - acc: 0.0000e+00 - val_loss: 27.2822 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 26.35696\n",
      "Epoch 40/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 1.6769 - acc: 0.0000e+00 - val_loss: 29.7844 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 26.35696\n",
      "Epoch 41/50\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 0.9712 - acc: 0.0000e+00 - val_loss: 29.9410 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 26.35696\n",
      "Epoch 42/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 1.1028 - acc: 0.0000e+00 - val_loss: 27.6095 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 26.35696\n",
      "Epoch 43/50\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.0322 - acc: 0.0000e+00 - val_loss: 29.2931 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 26.35696\n",
      "Epoch 44/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 0.8946 - acc: 0.0000e+00 - val_loss: 27.1661 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 26.35696\n",
      "Epoch 45/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 0.9155 - acc: 0.0000e+00 - val_loss: 28.8438 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 26.35696\n",
      "Epoch 46/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 0.9302 - acc: 0.0000e+00 - val_loss: 29.2551 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 26.35696\n",
      "Epoch 47/50\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 0.7684 - acc: 0.0000e+00 - val_loss: 28.5570 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 26.35696\n",
      "Epoch 48/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 0.8291 - acc: 0.0000e+00 - val_loss: 30.9056 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 26.35696\n",
      "Epoch 49/50\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.4202 - acc: 0.0000e+00 - val_loss: 27.4141 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 26.35696\n",
      "Epoch 50/50\n",
      "311/311 [==============================] - 2s 5ms/step - loss: 1.6910 - acc: 0.0000e+00 - val_loss: 27.5210 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 26.35696\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(checkpoint_folder):\n",
    "    os.makedirs(checkpoint_folder)\n",
    "\n",
    "filepath=checkpoint_folder+\"/weights-{epoch:02d}.hdf5\"\n",
    "# if train_model:\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#opt = RMSprop(lr=0.0,rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "if type_of_input == 'video':\n",
    "    video_model.compile(loss='mse',metrics=['mae'],optimizer=opt)\n",
    "elif type_of_input == 'frame':\n",
    "    dummy_model.compile(loss='mse',metrics=['accuracy'],optimizer=opt)\n",
    "\n",
    "#model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "checkpoint = \\\n",
    "    ModelCheckpoint(filepath, verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "lr = LearningRateScheduler(step_decay(initial_lrate,epochs_drop,drop_factor))\n",
    "\n",
    "#  APURVA\n",
    "# history = Frame_model.fit(train_imgs, train_labels,callbacks=[checkpoint,lr,TerminateOnNaN()],\n",
    "#           validation_data=(validation_imgs,validation_labels),\n",
    "#           batch_size=batch_size, epochs=epochs,shuffle=True)\n",
    "\n",
    "# ADAM\n",
    "print()\n",
    "history = dummy_model.fit(train_imgs_crops_res, train_labels,callbacks=[checkpoint,lr,TerminateOnNaN()],\n",
    "          validation_data=(validation_imgs_crops_res, validation_labels),\n",
    "          batch_size=batch_size, epochs=50,shuffle=True)\n",
    "# history = video_model.fit(train_videos, train_videos_labels,callbacks=[checkpoint,lr,TerminateOnNaN()],\n",
    "#           validation_data=(validation_videos,validation_videos_labels),\n",
    "#           batch_size=batch_size, epochs=epochs,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True=77.1938400448124, Predicted=[26.953377]\n",
      "True=102.7519164554348, Predicted=[26.934359]\n",
      "True=102.7519164554348, Predicted=[26.940372]\n",
      "True=82.21418663880205, Predicted=[26.949389]\n",
      "True=82.21418663880205, Predicted=[26.951986]\n",
      "True=70.95870147644602, Predicted=[26.937592]\n",
      "True=74.10904526666386, Predicted=[26.965221]\n",
      "True=86.9765613362632, Predicted=[26.931103]\n",
      "True=76.6035011342479, Predicted=[26.933493]\n",
      "True=76.34763844275375, Predicted=[26.944248]\n",
      "True=73.57620273986909, Predicted=[26.948864]\n",
      "True=70.71924384116333, Predicted=[26.92424]\n"
     ]
    }
   ],
   "source": [
    "Ynew = video_model.predict(validation_videos)\n",
    "# show the inputs and predicted outputs\n",
    "for i in range(len(validation_videos)):\n",
    "    print(\"True=%s, Predicted=%s\" % (validation_videos_labels[i], Ynew[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True=73.25523767440694, Predicted=[71.599556]\n",
      "True=73.25523767440694, Predicted=[69.644]\n",
      "True=73.25523767440694, Predicted=[72.07249]\n",
      "True=80.44922366806699, Predicted=[82.363655]\n",
      "True=80.44922366806699, Predicted=[83.06998]\n",
      "True=80.44922366806699, Predicted=[80.53925]\n",
      "True=80.44922366806699, Predicted=[73.81894]\n",
      "True=84.74102379560351, Predicted=[84.90053]\n",
      "True=84.74102379560351, Predicted=[80.85953]\n",
      "True=71.6790492593985, Predicted=[71.89114]\n",
      "True=77.1938400448124, Predicted=[73.6715]\n",
      "True=77.1938400448124, Predicted=[77.74444]\n",
      "True=77.1938400448124, Predicted=[80.328606]\n",
      "True=77.1938400448124, Predicted=[74.739876]\n",
      "True=75.07288766535675, Predicted=[76.482605]\n",
      "True=75.07288766535675, Predicted=[71.59193]\n",
      "True=75.07288766535675, Predicted=[84.38763]\n",
      "True=62.133284639290245, Predicted=[63.93198]\n",
      "True=62.133284639290245, Predicted=[62.06683]\n",
      "True=61.39248667646541, Predicted=[60.929028]\n",
      "True=61.39248667646541, Predicted=[63.087093]\n",
      "True=61.39248667646541, Predicted=[56.62547]\n",
      "True=61.39248667646541, Predicted=[58.935467]\n",
      "True=102.7519164554348, Predicted=[102.662674]\n",
      "True=102.7519164554348, Predicted=[102.581764]\n",
      "True=88.17286702598886, Predicted=[85.45616]\n",
      "True=88.17286702598886, Predicted=[86.8857]\n",
      "True=88.17286702598886, Predicted=[79.82423]\n",
      "True=82.21418663880205, Predicted=[80.39486]\n",
      "True=82.21418663880205, Predicted=[83.69624]\n",
      "True=82.21418663880205, Predicted=[83.87299]\n",
      "True=74.70742870540795, Predicted=[75.03192]\n",
      "True=70.95870147644602, Predicted=[67.52883]\n",
      "True=70.95870147644602, Predicted=[71.15849]\n",
      "True=70.95870147644602, Predicted=[74.82227]\n",
      "True=85.32308898899659, Predicted=[84.25356]\n",
      "True=74.10904526666386, Predicted=[74.01431]\n",
      "True=76.2588645555962, Predicted=[68.571175]\n",
      "True=76.2588645555962, Predicted=[76.321686]\n",
      "True=76.2588645555962, Predicted=[75.887215]\n",
      "True=86.9765613362632, Predicted=[86.28792]\n",
      "True=86.9765613362632, Predicted=[87.389244]\n",
      "True=86.9765613362632, Predicted=[82.85294]\n",
      "True=86.9765613362632, Predicted=[80.926544]\n",
      "True=62.046538044625215, Predicted=[60.059086]\n",
      "True=62.046538044625215, Predicted=[63.92905]\n",
      "True=62.046538044625215, Predicted=[60.24662]\n",
      "True=62.046538044625215, Predicted=[62.9279]\n",
      "True=76.6035011342479, Predicted=[78.07855]\n",
      "True=76.6035011342479, Predicted=[75.40444]\n",
      "True=76.6035011342479, Predicted=[74.64684]\n",
      "True=76.6035011342479, Predicted=[74.68578]\n",
      "True=76.6035011342479, Predicted=[73.698]\n",
      "True=95.52373198100672, Predicted=[92.95082]\n",
      "True=95.52373198100672, Predicted=[81.57611]\n",
      "True=77.15815201522035, Predicted=[77.464195]\n",
      "True=77.15815201522035, Predicted=[77.837265]\n",
      "True=76.34763844275375, Predicted=[82.290375]\n",
      "True=76.34763844275375, Predicted=[80.86292]\n",
      "True=76.34763844275375, Predicted=[75.91852]\n",
      "True=73.75502091473605, Predicted=[74.13637]\n",
      "True=73.75502091473605, Predicted=[73.98532]\n",
      "True=69.94689248043511, Predicted=[65.58662]\n",
      "True=69.94689248043511, Predicted=[68.978485]\n",
      "True=69.94689248043511, Predicted=[66.96786]\n",
      "True=75.84350312985775, Predicted=[74.48864]\n",
      "True=68.6030908380578, Predicted=[69.20269]\n",
      "True=68.6030908380578, Predicted=[68.62252]\n",
      "True=68.6030908380578, Predicted=[68.490814]\n",
      "True=62.19011215005239, Predicted=[76.968575]\n",
      "True=62.19011215005239, Predicted=[65.02785]\n",
      "True=63.683676891635045, Predicted=[62.552128]\n",
      "True=81.6561088686743, Predicted=[83.06336]\n",
      "True=81.6561088686743, Predicted=[79.90105]\n",
      "True=81.6561088686743, Predicted=[80.48552]\n",
      "True=80.18111269532929, Predicted=[75.5878]\n",
      "True=80.18111269532929, Predicted=[76.70742]\n",
      "True=80.18111269532929, Predicted=[80.55589]\n",
      "True=97.64540233497351, Predicted=[97.140625]\n",
      "True=97.64540233497351, Predicted=[63.654297]\n",
      "True=61.400407771763895, Predicted=[59.573795]\n",
      "True=61.400407771763895, Predicted=[58.790924]\n",
      "True=73.57620273986909, Predicted=[72.96612]\n",
      "True=73.57620273986909, Predicted=[73.83185]\n",
      "True=70.71924384116333, Predicted=[81.00641]\n"
     ]
    }
   ],
   "source": [
    "Ynew = dummy_model.predict(validation_imgs_crops_res)\n",
    "# show the inputs and predicted outputs\n",
    "for i in range(len(validation_imgs_crops_res)):\n",
    "    print(\"True=%s, Predicted=%s\" % (validation_labels[i], Ynew[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(conv_dim, kernel_size=kernel_size, input_shape=input_shape, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Dropout(dropout_amount))\n",
    "# model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same',kernel_regularizer=reg))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same',kernel_regularizer=reg))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Dropout(dropout_amount))\n",
    "# model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same',kernel_regularizer=reg))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(conv_dim,kernel_size=kernel_size,padding='same',kernel_regularizer=reg))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=3))\n",
    "# model.add(Dropout(dropout_amount))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(last_layer_dim,activation='relu'))\n",
    "# model.add(Dense(18, activation='softmax'))\n",
    "\n",
    "\n",
    "# from skimage import data, color\n",
    "# from skimage.transform import rescale, resize, downscale_local_mean\n",
    "# arr = train_imgs[0]\n",
    "# #arr_resize = scipy.misc.imresize(arr,(224,224,3))\n",
    "# image_resized = resize(arr, (224,224,3), anti_aliasing=false)\n",
    "\n",
    "# print('train images shape : ',train_imgs.shape)\n",
    "# print('validation images shape : ',validation_imgs.shape)\n",
    "\n",
    "# # RESHAPE FOR VGG16\n",
    "# train_imgs_crops_res = train_imgs[:,16::2, 50:274, :]\n",
    "# train_imgs_crops_res = train_imgs_crops_res[:,0:224, :, :]\n",
    "# validation_imgs_crops_res = validation_imgs[:,16::2, 50:274, :]\n",
    "# validation_imgs_crops_res = validation_imgs_crops_res[:,0:224, :, :]\n",
    "\n",
    "# print(train_imgs_crops_res.shape)\n",
    "# print(validation_imgs_crops_res.shape)\n",
    "\n",
    "# print(train_videos.shape)\n",
    "# print(train_videos_labels.shape)\n",
    "# # validation_videos=videos[~msk]\n",
    "# validation_videos_labels=labels[~msk]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
